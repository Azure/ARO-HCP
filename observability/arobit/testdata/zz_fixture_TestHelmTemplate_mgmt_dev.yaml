---
# Source: arobit/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: 'arobit-forwarder'
  namespace: 'arobit'
  labels:
    app.kubernetes.io/name: 'arobit-forwarder'
    app.kubernetes.io/instance: 'mgmt-dev'
  annotations:
    azure.workload.identity/client-id: 'bbbeb9f1-95b5-41af-8df7-bbf1a97da822'
---
# Source: arobit/templates/forwarder-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: arobit-forwarder
  namespace: 'arobit'
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
data:
  fluent-bit.conf: |
    @INCLUDE /forwarder/etc/service.conf

    @INCLUDE /forwarder/etc/input.conf

    @INCLUDE /forwarder/etc/filter.conf
    @INCLUDE /forwarder/etc/output.conf
  service.conf: |
    [SERVICE]
        Flush                     1
        Log_Level                 info
        Parsers_File              /fluent-bit/etc/parsers.conf
        Parsers_File              /forwarder/etc/parsers_custom.conf
        Plugins_File              /fluent-bit/etc/plugins.conf
        HTTP_Server               On
        storage.path              /var/log/flb-storage/
        # If the input plugin has enabled filesystem storage type, this property sets the maximum number of Chunks that can be up in memory.
        # (default: 128)
        storage.max_chunks_up     256
        # This option configure a hint of maximum value of memory to use when processing the backlog data.
        # (default: 5M)
        storage.backlog.mem_limit 256M
        storage.metrics           on
        # Based on the HC_Period, if the error number > HC_Errors_Count or the retry failure > HC_Retry_Failure_Count, fluent bit is considered as unhealthy.
        Health_Check              On
        HC_Errors_Count           5
        HC_Retry_Failure_Count    5
        HC_Period                 60
  parsers_custom.conf: |
    # Previously, docker parser would parse the container log as record["log"].
    # With the default cri parser, the container log will be parsed as record["message"].
    # For backward compat with docker implementation, use the following parser.
    [PARSER]
        Name        cri-o
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
        Time_Keep   On
    
    [PARSER]
        Name        containerlogs
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On
    
  input.conf: |
    [INPUT]
        Name              tail
        Alias             tail.container
        Tag               kubernetes.*
        Path              /var/log/containers/*.log
        Exclude_Path      /var/log/containers/*log-tailer*,/var/log/containers/*geneva-logger*,/var/log/containers/*arobit*
        Parser            cri-o
        # Docker_Mode       On
        # Parser            none
        DB                /var/log/flb-tail.db
        DB.sync           normal
        DB.locking        true
        # The interval of refreshing the list of watched files in seconds.
        # (default: 60)
        Refresh_Interval  15
        # For new discovered files on start (without a database offset/position), read the content from the head of the file.
        # (default: off)
        Read_from_Head    On
        # Set the initial buffer size to read files data. This value is used to increase buffer size.
        # (default: 32K)
        Buffer_Chunk_Size 1M
        # Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines),
        # this value is used to restrict how much the memory buffer can grow.
        # (default: Buffer_Chunk_Size)
        Buffer_Max_Size   4M
        # When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file.
        # Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.
        # (default: Off)
        Skip_Long_Lines   On
        # Set a limit of memory that Tail plugin can use when appending data to the Engine.
        # If the limit is reach, it will be paused; when the data is flushed it resumes.
        Mem_Buf_Limit     512M
        storage.type      filesystem
        # The new threaded mechanism allows input plugins to run in a separate thread which helps to desaturate the main pipeline
        Threaded          On

    [INPUT]
        Name              forward
        Alias             input.forward
        Listen            0.0.0.0
        Port              24224
        # By default, the buffer to store the incoming Forward messages, do not allocate the maximum memory allowed,
        # instead it allocate memory when is required. The rounds of allocations are set by Buffer_Chunk_Size.
        # (default: 32KB)
        Buffer_Chunk_Size 1M
        # Specify the maximum buffer memory size used to receive a Forward message.
        # (default: Buffer_Chunk_Size)
        Buffer_Max_Size   16M
        Mem_Buf_Limit     512M

    [INPUT]
        Name            fluentbit_metrics
        Alias           metrics.fluentbit
        Tag             metrics.fluentbit
        scrape_interval 15

    [INPUT]
        Name   opentelemetry
        Alias  otlp
        Listen 0.0.0.0
        Port   4318
  filter.conf: |
    [FILTER]
        Name   lua
        Alias  lua.reassemble_cri
        Match  kubernetes.var.log.containers.*
        script /forwarder/etc/reassemble_cri.lua
        call   reassemble_cri
    
    [FILTER]
        Name modify
        Match kubernetes.var.log.containers.*
        Add environment 
        Add region 
        Add cluster 

    [FILTER]
        Name                kubernetes
        Alias               filter.kubernetes
        Match               kubernetes.var.log.containers.*
        Kube_Tag_Prefix     kubernetes.var.log.containers.
        Annotations         Off
        K8S-Logging.Exclude On
        Buffer_Size         64k
    [FILTER]
        Name            rewrite_tag
        Alias           filter.namespace_router
        Match           kubernetes.var.log.containers.*
        Rule            $kubernetes['namespace_name'] ^ocm-.* ocm.logs false
        Rule            $kubernetes['namespace_name'] ^(?!ocm-).* other.logs false
        Emitter_Name    re_emitted_namespace_router

    [FILTER]
        # Other logs are keept, because want to send them to mdsd as well
        Name            rewrite_tag
        Alias           filter.container_name_router
        Match           other.logs
        Rule            $kubernetes['container_name'] ^aro-hcp-frontend* aro-hcp-frontend.logs true
        Rule            $kubernetes['container_name'] ^aro-hcp-backend* aro-hcp-backend.logs true
        Rule            $kubernetes['container_name'] ^kube-events* kube-events.logs true
        Emitter_Name    re_emitted_container_name_router

    [FILTER]
        # Parse the log key and make it a json object again under $
        Name Parser
        Match_regex (aro-hcp-(frontend|backend)|kube-events)\.logs
        Key_Name log
        Parser containerlogs
        Preserve_Key On
        Reserve_Data On
  output.conf: |
    [OUTPUT]
        Name  prometheus_exporter
        Alias exporter.fluentbit
        Match metrics.fluentbit
        Host  0.0.0.0
        Port  9090
    [OUTPUT]
        Match aro-hcp-frontend.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id edeb6da8-a476-4c67-9e2a-d61b8ff3315d
        client_id bbbeb9f1-95b5-41af-8df7-bbf1a97da822
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint http://ingest
        Database_Name rpDB
        Table_Name frontendContainerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

    [OUTPUT]
        Match aro-hcp-backend.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id edeb6da8-a476-4c67-9e2a-d61b8ff3315d
        client_id bbbeb9f1-95b5-41af-8df7-bbf1a97da822
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint http://ingest
        Database_Name rpDB
        Table_Name backendContainerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto
    [OUTPUT]
        Match other.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id edeb6da8-a476-4c67-9e2a-d61b8ff3315d
        client_id bbbeb9f1-95b5-41af-8df7-bbf1a97da822
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint http://ingest
        Database_Name rpDB
        Table_Name containerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

    [OUTPUT]
        Match kube-events.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id edeb6da8-a476-4c67-9e2a-d61b8ff3315d
        client_id bbbeb9f1-95b5-41af-8df7-bbf1a97da822
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint http://ingest
        Database_Name rpDB
        Table_Name kubernetesEvents
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto
  output-mdsd.conf: |
    # Forward logs to mdsd instance (default port)
    [OUTPUT]
        Name  forward
        Alias forward.mdsd.other
        Match other.logs
        Host  127.0.0.1
        Port  5001
        Tag   akskubesystem

    [OUTPUT]
        Name  prometheus_exporter
        Alias exporter.fluentbit
        Match metrics.fluentbit
        Host  0.0.0.0
        Port  9090
  output-mdsd-ocm.conf: |
    # Forward OCM namespace logs (ocm-.* pattern) to another mdsd instance
    [OUTPUT]
        Name  forward
        Alias forward.mdsd.ocm
        Match ocm.logs
        Host  127.0.0.1
        Port  5002
        Tag   akskubesystem
  reassemble_cri.lua: |
    local reassemble_state = {}
    function reassemble_cri(tag, timestamp, record)
      local reassemble_key = tag
      -- if partial line, accumulate
      if record.logtag == 'P' then
        reassemble_state[reassemble_key] = (reassemble_state[reassemble_key] or "") .. (record.log or "")
        return -1, 0, 0
      end
      -- otherwise, it's a full line, concatenate with accumulated partial lines if any
      record.log = (reassemble_state[reassemble_key] or "") .. (record.log or "")
      reassemble_state[reassemble_key] = nil
      return 1, timestamp, record
    end
---
# Source: arobit/templates/forwarder-clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: arobit-forwarder
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
rules:
- apiGroups:
  - ""
  resources:
  - "namespaces"
  - "services"
  - "pods"
  verbs:
  - "get"
  - "watch"
  - "list"
---
# Source: arobit/templates/forwarder-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: arobit-forwarder
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
roleRef:
  kind: ClusterRole
  apiGroup: rbac.authorization.k8s.io
  name: arobit-forwarder
subjects:
- kind: ServiceAccount
  name: 'arobit-forwarder'
  namespace: 'arobit'
---
# Source: arobit/templates/forwarder-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: arobit-forwarder
  namespace: 'arobit'
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
    app: arobit-forwarder
spec:
  type: ClusterIP
  ports:
  - name: otlp-http
    port: 4318
    targetPort: otlp-http
    protocol: TCP
  - name: forward
    port: 24224
    targetPort: forward
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: 9090
    protocol: TCP
  selector:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
---
# Source: arobit/templates/forwarder-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: arobit-forwarder
  namespace: 'arobit'
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: 'mgmt-dev'
    ## Istio Labels: https://istio.io/docs/ops/deployment/requirements/
    app: arobit-forwarder
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: arobit-forwarder
      app.kubernetes.io/instance: 'mgmt-dev'
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 100%
  template:
    metadata:
      labels:
        app.kubernetes.io/name: arobit-forwarder
        app.kubernetes.io/instance: 'mgmt-dev'
        app: arobit-forwarder
        azure.workload.identity/use: "true"
    spec:
      serviceAccountName: 'arobit-forwarder'
      shareProcessNamespace: true
      containers:
        - name: fluentbit
          image: foobar.azurecr.io/foobar/fluent-bit@sha256:foobar
          imagePullPolicy: ''
          command:
            - /fluent-bit/bin/fluent-bit
          args:
            - -c
            - /forwarder/etc/fluent-bit.conf
          ports:
            - name: http
              containerPort: 2020
              protocol: TCP
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            - name: forward
              containerPort: 24224
              protocol: TCP
            - name: metrics
              containerPort: 9090
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/v1/health
              port: http
            initialDelaySeconds: 15
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          readinessProbe:
            httpGet:
              path: /api/v1/health
              port: http
            initialDelaySeconds: 15
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 6
            successThreshold: 1
          securityContext: 
            privileged: false
            allowPrivilegeEscalation: false
            runAsUser: 0
            runAsGroup: 0
            capabilities:
              drop: ['ALL']
          volumeMounts:
            - name: varlog
              mountPath: /var/log
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
            - name: flb-config
              mountPath: /forwarder/etc
              readOnly: true
      volumes:
        - name: sp-host
          hostPath:
            type: Directory
            path: /etc/kubernetes/
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: cacrt-host
          hostPath:
            type: File
            path: /etc/ssl/certs/ca-certificates.crt
        - name: mdsd-run
          emptyDir: {}
        - name: flb-config
          configMap:
            name: arobit-forwarder
            defaultMode: 0755
---
# Source: arobit/templates/forwarder-secretprovider.yaml
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: arobit-secretprovider
  namespace: 'arobit'
spec:
  provider: azure
  parameters:
    clientID: 'bbbeb9f1-95b5-41af-8df7-bbf1a97da822'
    keyvaultName: "test"
    objects: |
      array:
        - |
          objectName: "foo"
          objectAlias: "gcscert.pem"
          objectType: secret
    tenantId: "edeb6da8-a476-4c67-9e2a-d61b8ff3315d"
    usePodIdentity: "false"
---
# Source: arobit/templates/forwarder-servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: arobit-forwarder
  namespace: 'arobit'
spec:
  endpoints:
  - interval: 30s
    path: /metrics
    port: metrics
    scheme: http
  namespaceSelector:
    matchNames:
    - 'arobit'
  selector:
    matchLabels:
      app: arobit-forwarder
