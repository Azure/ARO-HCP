---
apiVersion: v1
kind: ConfigMap
metadata:
  name: arobit-forwarder
  namespace: '{{ .Release.Namespace }}'
  labels:
    app.kubernetes.io/name: arobit-forwarder
    app.kubernetes.io/instance: '{{ .Release.Name }}'
data:
  fluent-bit.conf: |
    @INCLUDE /forwarder/etc/service.conf

    @INCLUDE /forwarder/etc/input.conf

    @INCLUDE /forwarder/etc/filter.conf

{{- if .Values.forwarder.mdsd.enabled }}
    @INCLUDE /forwarder/etc/output-mdsd.conf
    
    {{- if .Values.forwarder.clusterType | eq "mgmt" }}
    @INCLUDE /forwarder/etc/output-mdsd-ocm.conf
    {{- end }}
{{- end }}
    @INCLUDE /forwarder/etc/output.conf
  service.conf: |
    [SERVICE]
        Flush                     1
        Log_Level                 info
        Parsers_File              /fluent-bit/etc/parsers.conf
        Parsers_File              /forwarder/etc/parsers_custom.conf
        Plugins_File              /fluent-bit/etc/plugins.conf
        HTTP_Server               On
        storage.path              /var/log/flb-storage/
        # If the input plugin has enabled filesystem storage type, this property sets the maximum number of Chunks that can be up in memory.
        # (default: 128)
        storage.max_chunks_up     256
        # This option configure a hint of maximum value of memory to use when processing the backlog data.
        # (default: 5M)
        storage.backlog.mem_limit 256M
        storage.metrics           on
        # Based on the HC_Period, if the error number > HC_Errors_Count or the retry failure > HC_Retry_Failure_Count, fluent bit is considered as unhealthy.
        Health_Check              On
        HC_Errors_Count           5
        HC_Retry_Failure_Count    5
        HC_Period                 60
  parsers_custom.conf: |
    # Previously, docker parser would parse the container log as record["log"].
    # With the default cri parser, the container log will be parsed as record["message"].
    # For backward compat with docker implementation, use the following parser.
    [PARSER]
        Name        cri-o
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
        Time_Keep   On
    
    [PARSER]
        Name        containerlogs
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On
    
  input.conf: |
    [INPUT]
        Name              tail
        Alias             tail.container
        Tag               kubernetes.*
        Path              /var/log/containers/*.log
        Exclude_Path      /var/log/containers/*log-tailer*,/var/log/containers/*geneva-logger*,/var/log/containers/*arobit*
        Parser            cri-o
        # Docker_Mode       On
        # Parser            none
        DB                /var/log/flb-tail.db
        DB.sync           normal
        DB.locking        true
        # The interval of refreshing the list of watched files in seconds.
        # (default: 60)
        Refresh_Interval  15
        # For new discovered files on start (without a database offset/position), read the content from the head of the file.
        # (default: off)
        Read_from_Head    On
        # Set the initial buffer size to read files data. This value is used to increase buffer size.
        # (default: 32K)
        Buffer_Chunk_Size 1M
        # Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines),
        # this value is used to restrict how much the memory buffer can grow.
        # (default: Buffer_Chunk_Size)
        Buffer_Max_Size   4M
        # When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file.
        # Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.
        # (default: Off)
        Skip_Long_Lines   On
        # Set a limit of memory that Tail plugin can use when appending data to the Engine.
        # If the limit is reach, it will be paused; when the data is flushed it resumes.
        Mem_Buf_Limit     512M
        storage.type      filesystem
        # The new threaded mechanism allows input plugins to run in a separate thread which helps to desaturate the main pipeline
        Threaded          On

    [INPUT]
        Name              forward
        Alias             input.forward
        Listen            0.0.0.0
        Port              24224
        # By default, the buffer to store the incoming Forward messages, do not allocate the maximum memory allowed,
        # instead it allocate memory when is required. The rounds of allocations are set by Buffer_Chunk_Size.
        # (default: 32KB)
        Buffer_Chunk_Size 1M
        # Specify the maximum buffer memory size used to receive a Forward message.
        # (default: Buffer_Chunk_Size)
        Buffer_Max_Size   16M
        Mem_Buf_Limit     512M

    [INPUT]
        Name            fluentbit_metrics
        Alias           metrics.fluentbit
        Tag             metrics.fluentbit
        scrape_interval 15

    [INPUT]
        Name   opentelemetry
        Alias  otlp
        Listen 0.0.0.0
        Port   4318
  filter.conf: |
    [FILTER]
        Name   lua
        Alias  lua.reassemble_cri
        Match  kubernetes.var.log.containers.*
        script /forwarder/etc/reassemble_cri.lua
        call   reassemble_cri
    
    [FILTER]
        Name                kubernetes
        Alias               filter.kubernetes
        Match               kubernetes.var.log.containers.*
        Kube_Tag_Prefix     kubernetes.var.log.containers.
        Annotations         Off
        K8S-Logging.Exclude On
        Buffer_Size         64k

    [FILTER]
        Name            rewrite_tag
        Alias           filter.namespace_router
        Match           kubernetes.var.log.containers.*
        Rule            $kubernetes['namespace_name'] ^ocm-.* ocm.logs false
        Rule            $kubernetes['namespace_name'] ^(?!ocm-).* other.logs false
        Emitter_Name    re_emitted_namespace_router

    [FILTER]
        # Other logs are keept, because want to send them to mdsd as well
        Name            rewrite_tag
        Alias           filter.container_name_router
        Match           other.logs
        Rule            $kubernetes['container_name'] ^aro-hcp-frontend* aro-hcp-frontend.logs true
        Rule            $kubernetes['container_name'] ^aro-hcp-backend* aro-hcp-backend.logs true
        Rule            $kubernetes['container_name'] ^kube-events* kube-events.logs true
        Emitter_Name    re_emitted_container_name_router

    [FILTER]
        # Parse the log key and make it a json object again under $
        Name Parser
        Match_regex (aro-hcp-(frontend|backend)|kube-events)\.logs
        Key_Name log
        Parser containerlogs
        Preserve_Key On
        Reserve_Data On
  output.conf: |
    [OUTPUT]
        Match other.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id {{ .Values.forwarder.secretProvider.tenantId }}
        client_id {{ .Values.forwarder.secretProvider.msiClientId }}
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint https://ingest-hcp-dev-kusto.westus3.kusto.windows.net
        Database_Name HCPServiceLogs
        Table_Name containerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

    [OUTPUT]
        Match aro-hcp-frontend.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id {{ .Values.forwarder.secretProvider.tenantId }}
        client_id {{ .Values.forwarder.secretProvider.msiClientId }}
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint https://ingest-hcp-dev-kusto.westus3.kusto.windows.net
        Database_Name HCPServiceLogs
        Table_Name frontendContainerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

    [OUTPUT]
        Match aro-hcp-backend.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id {{ .Values.forwarder.secretProvider.tenantId }}
        client_id {{ .Values.forwarder.secretProvider.msiClientId }}
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint https://ingest-hcp-dev-kusto.westus3.kusto.windows.net
        Database_Name HCPServiceLogs
        Table_Name backendContainerLogs
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

    [OUTPUT]
        Match kube-events.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id {{ .Values.forwarder.secretProvider.tenantId }}
        client_id {{ .Values.forwarder.secretProvider.msiClientId }}
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint https://ingest-hcp-dev-kusto.westus3.kusto.windows.net
        Database_Name HCPServiceLogs
        Table_Name kubernetesEvents
        ingestion_mapping_reference ingestionMapping
        buffer_dir /var/kusto

  output-mdsd.conf: |
    [OUTPUT]
        Match other.logs
        Name azure_kusto
        auth_type workload_identity
        tenant_id {{ .Values.forwarder.secretProvider.tenantId }}
        client_id {{ .Values.forwarder.secretProvider.msiClientId }}
        workload_identity_token_file /var/run/secrets/azure/wi/token/azure-identity-token
        Ingestion_Endpoint https://ingest-hcp-dev-kusto.westus3.kusto.windows.net
        Database_Name HCPCustomerLogs
        Table_Name containerLogs
        buffer_dir /var/kusto

  output-mdsd.conf: |
    # Forward logs to mdsd instance (default port)
    [OUTPUT]
        Name  forward
        Alias forward.mdsd.other
        Match other.logs
        Host  127.0.0.1
        Port  5001
        Tag   akskubesystem

    [OUTPUT]
        Name  prometheus_exporter
        Alias exporter.fluentbit
        Match metrics.fluentbit
        Host  0.0.0.0
        Port  2020
  output-mdsd-ocm.conf: |
    # Forward OCM namespace logs (ocm-.* pattern) to another mdsd instance
    [OUTPUT]
        Name  forward
        Alias forward.mdsd.ocm
        Match ocm.logs
        Host  127.0.0.1
        Port  5002
        Tag   akskubesystem
  reassemble_cri.lua: |
    local reassemble_state = {}
    function reassemble_cri(tag, timestamp, record)
      local reassemble_key = tag
      -- if partial line, accumulate
      if record.logtag == 'P' then
        reassemble_state[reassemble_key] = (reassemble_state[reassemble_key] or "") .. (record.log or "")
        return -1, 0, 0
      end
      -- otherwise, it's a full line, concatenate with accumulated partial lines if any
      record.log = (reassemble_state[reassemble_key] or "") .. (record.log or "")
      reassemble_state[reassemble_key] = nil
      return 1, timestamp, record
    end