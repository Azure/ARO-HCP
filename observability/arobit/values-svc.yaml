# Global Docker image parameters
##
# imagePullSecrets:
#   - linuxgeneva-microsoft
forwarder:
  clusterType: "svc"
  ## Enable forwarder daemonset
  ##
  dynamicConfig: false
  ## K8s Security Context for forwarder pods
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ##
  securityContext:
    enabled: true
    runAsUser: 65532
    runAsGroup: 65532
  ## Pods Service Account
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccountName: arobit-forwarder
  fluentbit:
    ## Fluent Bit image version
    ##
    image:
      registry: "{{ .arobit.forwarder.image.registry }}"
      repository: "{{ .arobit.forwarder.image.repository }}"
      digest: "{{ .arobit.forwarder.image.digest }}"
      pullPolicy: IfNotPresent
    ## The configMap that contains the configuration files for fluent-bit
    ##
    configMap:
      service.conf: |
        [SERVICE]
            Flush                     1
            Log_Level                 info
            Parsers_File              /fluent-bit/etc/parsers.conf
            Parsers_File              /forwarder/etc/parsers_custom.conf
            Plugins_File              /fluent-bit/etc/plugins.conf
            HTTP_Server               On
            storage.path              /var/log/flb-storage/
            # If the input plugin has enabled filesystem storage type, this property sets the maximum number of Chunks that can be up in memory.
            # (default: 128)
            storage.max_chunks_up     256
            # This option configure a hint of maximum value of memory to use when processing the backlog data.
            # (default: 5M)
            storage.backlog.mem_limit 256M
            storage.metrics           on
            # Based on the HC_Period, if the error number > HC_Errors_Count or the retry failure > HC_Retry_Failure_Count, fluent bit is considered as unhealthy.
            Health_Check              On
            HC_Errors_Count           5
            HC_Retry_Failure_Count    5
            HC_Period                 60
      parsers_custom.conf: |
        [PARSER]
            Name                nested_time_field
            Format              json
            Time_Key            time
            Time_Format         %Y-%m-%dT%H:%M:%S.%L
      input.conf: |
        [INPUT]
            Name              tail
            Alias             tail.container
            Tag               kubernetes.*
            Path              /var/log/containers/*.log
            Exclude_Path      /var/log/containers/*log-tailer*,/var/log/containers/*geneva-logger*,/var/log/containers/*arobit*
            # For kubernetes version < 1.19.x, use 'docker' parser instead:
            # Parser            docker
            # Docker_Mode       On
            Parser            cri-o
            DB                /var/log/flb-tail.db
            DB.sync           normal
            DB.locking        true
            # The interval of refreshing the list of watched files in seconds.
            # (default: 60)
            Refresh_Interval  15
            # For new discovered files on start (without a database offset/position), read the content from the head of the file.
            # (default: off)
            Read_from_Head    On
            # Set the initial buffer size to read files data. This value is used to increase buffer size.
            # (default: 32K)
            Buffer_Chunk_Size 1M
            # Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines),
            # this value is used to restrict how much the memory buffer can grow.
            # (default: Buffer_Chunk_Size)
            Buffer_Max_Size   4M
            # When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file.
            # Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.
            # (default: Off)
            Skip_Long_Lines   On
            # Set a limit of memory that Tail plugin can use when appending data to the Engine.
            # If the limit is reach, it will be paused; when the data is flushed it resumes.
            Mem_Buf_Limit     512M
            storage.type      filesystem
            # The new threaded mechanism allows input plugins to run in a separate thread which helps to desaturate the main pipeline
            Threaded          On

        [INPUT]
            Name              forward
            Alias             input.forward
            Listen            0.0.0.0
            Port              24224
            # By default, the buffer to store the incoming Forward messages, do not allocate the maximum memory allowed,
            # instead it allocate memory when is required. The rounds of allocations are set by Buffer_Chunk_Size.
            # (default: 32KB)
            Buffer_Chunk_Size 1M
            # Specify the maximum buffer memory size used to receive a Forward message.
            # (default: Buffer_Chunk_Size)
            Buffer_Max_Size   16M
            Mem_Buf_Limit     512M

        [INPUT]
            Name            fluentbit_metrics
            Alias           metrics.fluentbit
            Tag             metrics.fluentbit
            scrape_interval 15

        [INPUT]
            Name   opentelemetry
            Alias  otlp
            Listen 0.0.0.0
            Port   4318
      filter.conf: |
        [FILTER]
            Name                kubernetes
            Alias               filter.kubernetes
            Match               kubernetes.var.log.containers.*
            Kube_Tag_Prefix     kubernetes.var.log.containers.
            Annotations         Off
            K8S-Logging.Exclude On
            Buffer_Size         64k

        [FILTER]
            Name          nest
            Match         kubernetes.*
            Operation     lift
            Nested_under  kubernetes

        [FILTER]
            Name          parser
            Alias         parser.nested_time_field
            Match         kubernetes.*
            Parser        nested_time_field
            Key_Name      log

        [FILTER]
            Name            rewrite_tag
            Alias           filter.namespace_router
            Match           kubernetes.var.log.containers.*
            Rule            namespace_name ^ocm-.* ocm.logs false
            Rule            namespace_name ^(?!ocm-).* other.logs false
            Emitter_Name    re_emitted
      output.conf: |
        [OUTPUT]
            Name       opentelemetry
            Match      *
            Host       ingest.observability
            Port       4318
            Traces_uri /v1/traces

        [OUTPUT]
            Name  prometheus_exporter
            Alias exporter.fluentbit
            Match metrics.fluentbit
            Host  0.0.0.0
            Port  2020
      output-mdsd.conf: |
        # Forward logs to mdsd instance (default port)
        [OUTPUT]
            Name  forward
            Alias forward.mdsd.other
            Match other.logs
            Host  127.0.0.1
            Port  5001
            Tag   akskubesystem

        [OUTPUT]
            Name  prometheus_exporter
            Alias exporter.fluentbit
            Match metrics.fluentbit
            Host  0.0.0.0
            Port  2020
      output-mdsd-ocm.conf: |
        # Forward OCM namespace logs (ocm-.* pattern) to another mdsd instance
        [OUTPUT]
            Name  forward
            Alias forward.mdsd.ocm
            Match ocm.logs
            Host  127.0.0.1
            Port  5002
            Tag   akskubesystem
  mdsd:
    # Geneva Config
    geneva:
      role: "{{ .svc.rg }}"
      rpAccountName: "{{ .geneva.logs.rp.accountName }}"
      rpSecretName: "{{ .geneva.logs.rp.secretName }}"
      rpSan: "{{ .geneva.logs.rp.san }}"
      rpNamespace: "{{ .geneva.logs.rp.namespace }}"
      clusterLogsAccountName: "{{ .geneva.logs.cluster.accountName }}"
      clusterLogsSecretName: "{{ .geneva.logs.cluster.secretName }}"
      clusterLogsSan: "{{ .geneva.logs.cluster.san }}"
      clusterLogsNamespace: "{{ .geneva.logs.cluster.namespace }}"
      configVersion: 1
      environment: "{{ .geneva.logs.environment }}"
      region: "{{ .region }}"
    ## Specifies whether mdsd should enabled
    enabled: {{ .arobit.mdsd.enabled }}
    ## mdsd image version
    ##
    image:
      registry: "{{ .arobit.mdsd.image.registry }}"
      repository: "{{ .arobit.mdsd.image.repository }}"
      digest: "{{ .arobit.mdsd.image.digest }}"
      pullPolicy: IfNotPresent
  secretProvider:
    msiClientId: "__msiClientId__"
    keyVault: "{{ .serviceKeyVault.name }}"
    tenantId: "__tenantId__"
