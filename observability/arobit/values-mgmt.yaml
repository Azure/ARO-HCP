# Global Docker image parameters
##
# imagePullSecrets:
#   - linuxgeneva-microsoft
forwarder:
  clusterType: "mgmt"
  ## Enable forwarder daemonset
  ##
  dynamicConfig: false
  ## K8s Security Context for forwarder pods
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  ##
  securityContext:
    enabled: true
    runAsUser: 65532
    runAsGroup: 65532
  ## Pods Service Account
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccountName: arobit-forwarder
  fluentbit:
    ## Fluent Bit image version
    ##
    image:
      registry: "{{ .arobit.forwarder.image.registry }}"
      repository: "{{ .arobit.forwarder.image.repository }}"
      digest: "{{ .arobit.forwarder.image.digest }}"
      pullPolicy: IfNotPresent
    ## The configMap that contains the configuration files for fluent-bit
    ##
    configMap:
      service.conf: |
        [SERVICE]
            Flush                     1
            Log_Level                 debug
            Parsers_File              /fluent-bit/etc/parsers.conf
            Parsers_File              /forwarder/etc/parsers_custom.conf
            Plugins_File              /fluent-bit/etc/plugins.conf
            HTTP_Server               On
            storage.path              /var/log/flb-storage/
            # If the input plugin has enabled filesystem storage type, this property sets the maximum number of Chunks that can be up in memory.
            # (default: 128)
            storage.max_chunks_up     256
            # This option configure a hint of maximum value of memory to use when processing the backlog data.
            # (default: 5M)
            storage.backlog.mem_limit 256M
            storage.metrics           on
            # Based on the HC_Period, if the error number > HC_Errors_Count or the retry failure > HC_Retry_Failure_Count, fluent bit is considered as unhealthy.
            Health_Check              On
            HC_Errors_Count           5
            HC_Retry_Failure_Count    5
            HC_Period                 60
      parsers_custom.conf: |
        # Previously, docker parser would parse the container log as record["log"].
        # With the default cri parser, the container log will be parsed as record["message"].
        # For backward compat with docker implementation, use the following parser.
        [PARSER]
            Name        cri-o
            Format      regex
            Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L%z
            Time_Keep   On
        
        [PARSER]
            Name        containerlogs
            Format      json
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L
            Time_Keep   On
        
      input.conf: |
        [INPUT]
            Name              tail
            Alias             tail.container
            Tag               kubernetes.*
            Path              /var/log/containers/*.log
            Exclude_Path      /var/log/containers/*log-tailer*,/var/log/containers/*geneva-logger*,/var/log/containers/*arobit*
            Parser            cri-o
            # Docker_Mode       On
            # Parser            none
            DB                /var/log/flb-tail.db
            DB.sync           normal
            DB.locking        true
            # The interval of refreshing the list of watched files in seconds.
            # (default: 60)
            Refresh_Interval  15
            # For new discovered files on start (without a database offset/position), read the content from the head of the file.
            # (default: off)
            Read_from_Head    On
            # Set the initial buffer size to read files data. This value is used to increase buffer size.
            # (default: 32K)
            Buffer_Chunk_Size 1M
            # Set the limit of the buffer size per monitored file. When a buffer needs to be increased (e.g: very long lines),
            # this value is used to restrict how much the memory buffer can grow.
            # (default: Buffer_Chunk_Size)
            Buffer_Max_Size   4M
            # When a monitored file reach it buffer capacity due to a very long line (Buffer_Max_Size), the default behavior is to stop monitoring that file.
            # Skip_Long_Lines alter that behavior and instruct Fluent Bit to skip long lines and continue processing other lines that fits into the buffer size.
            # (default: Off)
            Skip_Long_Lines   On
            # Set a limit of memory that Tail plugin can use when appending data to the Engine.
            # If the limit is reach, it will be paused; when the data is flushed it resumes.
            Mem_Buf_Limit     512M
            storage.type      filesystem
            # The new threaded mechanism allows input plugins to run in a separate thread which helps to desaturate the main pipeline
            Threaded          On

        [INPUT]
            Name              forward
            Alias             input.forward
            Listen            0.0.0.0
            Port              24224
            # By default, the buffer to store the incoming Forward messages, do not allocate the maximum memory allowed,
            # instead it allocate memory when is required. The rounds of allocations are set by Buffer_Chunk_Size.
            # (default: 32KB)
            Buffer_Chunk_Size 1M
            # Specify the maximum buffer memory size used to receive a Forward message.
            # (default: Buffer_Chunk_Size)
            Buffer_Max_Size   16M
            Mem_Buf_Limit     512M

        [INPUT]
            Name            fluentbit_metrics
            Alias           metrics.fluentbit
            Tag             metrics.fluentbit
            scrape_interval 15

        [INPUT]
            Name   opentelemetry
            Alias  otlp
            Listen 0.0.0.0
            Port   4318
      filter.conf: |
        [FILTER]
            Name   lua
            Alias  lua.reassemble_cri
            Match  kubernetes.var.log.containers.*
            script /forwarder/etc/reassemble_cri.lua
            call   reassemble_cri
        
        [FILTER]
            Name                kubernetes
            Alias               filter.kubernetes
            Match               kubernetes.var.log.containers.*
            Kube_Tag_Prefix     kubernetes.var.log.containers.
            Annotations         Off
            K8S-Logging.Exclude On
            Buffer_Size         64k

        [FILTER]
            Name            rewrite_tag
            Alias           filter.namespace_router
            Match           kubernetes.var.log.containers.*
            Rule            $kubernetes['namespace_name'] ^ocm-.* ocm.logs false
            Rule            $kubernetes['namespace_name'] ^(?!ocm-).* other.logs false
            Emitter_Name    re_emitted_namespace_router

        [FILTER]
            # Other logs are keept, because want to send them to mdsd as well
            Name            rewrite_tag
            Alias           filter.container_name_router
            Match           other.logs
            Rule            $kubernetes['container_name'] ^aro-hcp-frontend* aro-hcp-frontend.logs true
            Rule            $kubernetes['container_name'] ^aro-hcp-backend* aro-hcp-backend.logs true
            Emitter_Name    re_emitted_container_name_router

        [FILTER]
            Name Parser
            Match aro-hcp-frontend.logs
            Key_Name log
            Parser containerlogs
            Preserve_Key On
            Reserve_Data On
      output.conf: |
        [OUTPUT]
            Name  stdout
            Match aro-hcp-frontend.logs
            format json

      output-azure-kusto.conf: |
          [FILTER]

          [OUTPUT]
            Name azure_kusto
            Match *
      output-mdsd.conf: |
        # Forward logs to mdsd instance (default port)
        [OUTPUT]
            Name  forward
            Alias forward.mdsd.other
            Match other.logs
            Host  127.0.0.1
            Port  5001
            Tag   akskubesystem

        [OUTPUT]
            Name  prometheus_exporter
            Alias exporter.fluentbit
            Match metrics.fluentbit
            Host  0.0.0.0
            Port  2020
      output-mdsd-ocm.conf: |
        # Forward OCM namespace logs (ocm-.* pattern) to another mdsd instance
        [OUTPUT]
            Name  forward
            Alias forward.mdsd.ocm
            Match ocm.logs
            Host  127.0.0.1
            Port  5002
            Tag   akskubesystem
      reassemble_cri.lua: |
        local reassemble_state = {}
        function reassemble_cri(tag, timestamp, record)
          local reassemble_key = tag
          -- if partial line, accumulate
          if record.logtag == 'P' then
            reassemble_state[reassemble_key] = (reassemble_state[reassemble_key] or "") .. (record.log or "")
            return -1, 0, 0
          end
          -- otherwise, it's a full line, concatenate with accumulated partial lines if any
          record.log = (reassemble_state[reassemble_key] or "") .. (record.log or "")
          reassemble_state[reassemble_key] = nil
          return 1, timestamp, record
        end
  mdsd:
    # Geneva Config
    geneva:
      role: "{{ .mgmt.rg }}"
      rpAccountName: "{{ .geneva.logs.rp.accountName }}"
      rpSecretName: "{{ .geneva.logs.rp.secretName }}"
      rpSan: "{{ .geneva.logs.rp.san }}"
      rpNamespace: "{{ .geneva.logs.rp.namespace }}"
      clusterLogsAccountName: "{{ .geneva.logs.cluster.accountName }}"
      clusterLogsSecretName: "{{ .geneva.logs.cluster.secretName }}"
      clusterLogsSan: "{{ .geneva.logs.cluster.san }}"
      clusterLogsNamespace: "{{ .geneva.logs.cluster.namespace }}"
      configVersion: 1
      environment: "{{ .geneva.logs.environment }}"
      region: "{{ .region }}"
    ## Specifies whether mdsd should enabled
    enabled: {{ .arobit.mdsd.enabled }}
    ## mdsd image version
    ##
    image:
      registry: "{{ .arobit.mdsd.image.registry }}"
      repository: "{{ .arobit.mdsd.image.repository }}"
      digest: "{{ .arobit.mdsd.image.digest }}"
      pullPolicy: IfNotPresent
  secretProvider:
    msiClientId: "__msiClientId__"
    keyVault: "{{ .mgmtKeyVault.name }}"
    tenantId: "__tenantId__"
