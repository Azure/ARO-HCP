$schema: config.schema.json
#
#   A B O U T   N A M I N G
#
# For Azure resource names that need to be unique within a cloud, use {{ .ctx }} variables to ensure uniqueness, e.g.
# - for global, regional and SC naming use {{ .ctx.regionShort }} or {{ .ctx.region }}
# - for MGMT naming additionally use {{ .ctx.stamp }}
#
# We have different requirements for naming uniqueness for Azure resources
#
# - [globally-unique] - a resource needs to be unique within the Azure cloud.
#   This is a technical requirement of Azure for certain resource types
# - [env-unique] - a resource needs to be unique within an ARO HCP environment,
#   so across all regions of ARO HCP in the same environment.
#   An environment unique names does not need to be unique within the Azure cloud
#
# To implement names, we leverage static strings combined with the {{ .ctx }} variables, e.g.
# - {{ .ctx.environment }} length: 1-4 / starts with a character, may end with a digit
# - {{ .ctx.regionShort }} length: 2-4 / starts with a character, may end with a digit
# - {{ .ctx.region }} very long, up to 20 characters / starts with a character, may end with a digit
# - {{ .ctx.stamp }} used for uniqueness for MGMT stamps within a region / digits only
defaults:
  #
  # All defaults in this section need to be environment and region agnostic.
  #
  azureGeoShortId: "{{ .ev2.geoShortId }}"
  environmentName: "{{ .ctx.environment }}"
  region: "{{ .ctx.region }}"
  regionRG: "{{ .ctx.region }}-shared-resources"
  regionBuildout: false
  cloud: "{{ .ev2.cloudName }}"
  azureRegionAvailabilityZoneCount: {{ .ev2.availabilityZoneCount }}
  keyVaultDNSSuffix: "{{ .ev2.keyVault.domainNameSuffix }}"
  acrDNSSuffix: "{{ .ev2.azureContainerRegistry.domainNameSuffix }}"
  administration:
    readerGroupId: ""
    releaseManagementGroupId: ""
  # Global scope settings
  global:
    safeDnsIntAppObjectId: "" # intentionally left empty
    subscription:
      key: hcp-global
      displayName: "Azure Red Hat OpenShift HCP - {{ .ctx.environment }} - Global"
      providers:
        'Microsoft.Dashboard':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
        'Microsoft.Kusto':
          poll: true
    rg: global-shared-resources
    billing:
      rg: "placeholder"
      digest: "placeholder"
    globalMSIName: global-ev2-identity
    nsp:
      name: nsp-global
      accessMode: 'Learning'
    keyVault:
      name: 'arohcp{{ .ctx.environment }}-global' # [globally-unique]
      private: false
      softDelete: true
      tagKey: aroHCPPurpose
      tagValue: global
  # ACR
  acr:
    svc:
      name: 'arohcpsvc{{ .ctx.environment }}' # [globally-unique]
      zoneRedundantMode: Enabled
      untaggedImagesRetention:
        enabled: false
        days: 365
    ocp:
      name: 'arohcpocp{{ .ctx.environment }}' # [globally-unique]
      zoneRedundantMode: Enabled
      untaggedImagesRetention:
        enabled: true
        days: 90
  # ACR Pull
  acrPull:
    image:
      registry: mcr.microsoft.com
      repository: aks/msi-acrpull
  # Arobit
  arobit:
    forwarder:
      image:
        registry: mcr.microsoft.com
        repository: oss/v2/fluent/fluent-bit
        digest: sha256:f501177ac50d0ce6927e8c3c56977d769c460725b8a0cb685c9bbc365422d876 # v4.2.2 (2026-01-08 15:54)
    kusto:
      enabled: false
      environmentName: "{{ .ctx.environment }}"
    mdsd:
      enabled: true
      image:
        registry: mcr.microsoft.com
        repository: geneva/distroless/mdsd
        digest: sha256:df394f7829a999743517e93a95e1ce476e5fd6c1f3539ee396bfffb742a7fd25 # 1.38.2-20260111-1 (2026-01-11 03:50)
  # Kube Events
  kubeEvents:
    enabled: true
    image:
      registry: kubernetesshared.azurecr.io
      repository: shared/kube-events
      digest: sha256:754ab00b9a24fc3519a381017b176c265d05e83108b1049b80aaaf2e81eba5f5 # 20260113.1 (2026-01-13 06:42)
  # Secret Sync Controller
  secretSyncController:
    image:
      registry: registry.k8s.io
      repository: secrets-store-sync/controller
    providerImage:
      registry: mcr.microsoft.com
      repository: oss/v2/azure/secrets-store/provider-azure
  # Backplane API
  backplaneAPI:
    image:
      registry: quay.io
      repository: app-sre/backplane-api
  tenantId: ""
  ev2:
    assistedId:
      certificate:
        keyVault: "empty-sentinel" # we don't need one in public cloud, but we need a value to validate the field
        name: ""
      applicationId: ""
      dstsHost: "{{ .ev2.geneva.actions.homeDsts.primary }}"
  geneva:
    principalId: ""
    resourceContributor: ""
    metrics:
      cluster:
        account: AzureRedHatOpenShiftCluster
      rp:
        account: AzureRedHatOpenShiftRP
    logs:
      administrators:
        alias:
        - AME\WEINONGW
        securityGroup: AME\TM-AzureRedHatOpenShift-Leads
      adminCertificateDomain: "geneva.keyvault.aro-hcp-global.azure.com"
      adminCertName: "geneva-logs-admin"
      manageCertificates: true
      certificateIssuer: Self
      certificateDomain: "geneva.keyvault.aro-hcp.azure.com"
      typeName: ""
      environment: "Test"
      cluster:
        secretName: clusterlogs
        accountName: placeholder
        namespace: ""
        san: ""
        configVersion: "1"
      rp:
        secretName: rplogs
        accountName: placeholder
        namespace: ""
        san: ""
        configVersion: "1"
    actions:
      serviceTag: GenevaActions
      keyVault:
        name: "arohcp{{ .ctx.environment }}-geneva-kv" # [globally-unique]
        private: false
        softDelete: true
        tagKey: aroHCPPurpose
        tagValue: geneva-actions
      certificate:
        name: genevaAction
        issuer: OneCertV2-PrivateCA
        manage: true
      allowedAcisExtensions: "AzureRedHatHypershiftExtension,Azure Red Hat Hypershift"
      genevaActionsPrincipalId: ""
      application:
        name: "arohcp-ga-{{ .ctx.environment }}" # [tenant unique]
        ownerIds: ""
        useSNI: true
        manage: true
  kusto:
    enableAutoScale: false
    manageInstance: false
    autoScaleMin: 2
    autoScaleMax: 10
    rg: "hcp-kusto-{{ .ctx.environment }}-{{ .ev2.geoShortId }}"
    kustoName: "hcp-{{ .ctx.environment }}-{{ .ev2.geoShortId }}"
    serviceLogsDatabase: "ServiceLogs"
    hostedControlPlaneLogsDatabase: "HostedControlPlaneLogs"
    adminGroups: ""
    viewerGroups: ""
    sku: ""
    tier: ""
  # Hypershift
  hypershift:
    image:
      registry: quay.io
      repository: redhat-services-prod/crt-redhat-acm-tenant/hypershift/hypershift-operator
    namespace: hypershift
    additionalInstallArg: '--enable-cpo-overrides'
    # By default we set it to empty as this tag is only required for msft environments. We override
    # this value in sdp pipelines for msft environments.
    sharedIngressIPTag: ''
  # Log settings
  logs:
    mdsd:
      namespace: arobit
      msiName: logs-mdsd
      serviceAccountName: arobit-forwarder
      cert:
        name: ""
        type: ""
        issuer: ""
      subscriptions: []
  # Monitoring
  monitoring:
    grafanaName: "arohcp-{{ .ctx.environment }}"
    # Format:
    #   Multiline string using '>-' YAML block scalar
    #   One item per line, formatted as: UUID/PrincipalType/RoleName
    # Our yaml formatter does not allow >- when there is no value, so remember
    # to chage "" to >- when you add a value.
    grafanaRoles: ""
    crossTenantSecurityGroup: ""
    svcWorkspaceName: 'services-{{ .ctx.region }}'
    hcpWorkspaceName: 'hcps-{{ .ctx.region }}'
    alertRuleOwningTeamTag: ""
    icm:
      manageConnection: true
      connectionName: ""
      connectionId: ""
      environment: ""
      sre:
        actionGroupName: ""
        actionGroupShortName: ""
        routingId: ""
        automitigationEnabled: ""
      sl:
        actionGroupName: ""
        actionGroupShortName: ""
        routingId: ""
        automitigationEnabled: ""
      msft:
        actionGroupName: ""
        actionGroupShortName: ""
        routingId: ""
        automitigationEnabled: ""
  # Route Monitor Operator
  routeMonitorOperator:
    operatorImage:
      registry: quay.io
      repository: app-sre/route-monitor-operator
      digest: sha256:5e94ff37bcb8c1ebebce0c7c1f33cef8e7cf163f1b0baf5b50c9b771ca112846
    blackboxExporterImage:
      registry: quay.io
      repository: prometheus/blackbox-exporter
      digest: sha256:b04a9fef4fa086a02fc7fcd8dcdbc4b7b35cc30cdee860fdc6a19dd8b208d63e
  # SVC cluster specifics
  svc:
    subscription:
      usePlannedQuota: true
      key: "hcp-{{ .ctx.environment }}-svc-{{ .ctx.region }}"
      displayName: "Azure Red Hat OpenShift HCP - {{ .ev2.regionFriendlyName }} - SVC"
      providers:
        'Microsoft.Insights':
          poll: true
        'Microsoft.Dashboard':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
        'Microsoft.DbForPostgreSQL':
          poll: true
    rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}-svc"
    nsp:
      name: nsp-{{ .ctx.regionShort }}-svc
    istio:
      istioctlVersion: "1.24.1"
      tag: "prod-stable"
      ingressGatewayIPAddressName: "aro-hcp-istio-ingress"
      ingressGatewayIPAddressIPTags: ""
    aks:
      name: "{{ .ctx.environment }}-{{ .ctx.region }}-svc-1" # [env-unique]
      vnetAddressPrefix: "10.128.0.0/14"
      subnetPrefix: "10.128.8.0/21"
      podSubnetPrefix: "10.128.64.0/18"
      kubernetesVersion: 1.32.5
      networkDataplane: "cilium"
      networkPolicy: "cilium"
      systemAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        poolCount: 3
        zones: ""
        zoneRedundantMode: "Auto"
      userAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        poolCount: 3
        zones: ""
        zoneRedundantMode: "Auto"
      infraAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D4ds_v5'
        osDiskSizeGB: 32
        poolCount: 2
        zones: ""
        zoneRedundantMode: "Auto"
      etcd:
        name: "ah-{{ .ctx.environment }}-se-{{ .ctx.regionShort }}-1" # [globally-unique]
        softDelete: true
        private: true
        tagKey: aroHCPPurpose
        tagValue: etcd-encryption
      clusterOutboundIPAddressIPTags: ""
    prometheus:
      namespace: prometheus
      namespaceNetworkPolicyGroup: ""
      prometheusOperator:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-operator
        version: ""
      prometheusSpec:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus
        version: ""
        resources:
          requests:
            cpu: NONE
            memory: NONE
          limits:
            cpu: NONE
            memory: NONE
        replicas: 2
        shards: 2
      prometheusConfigReloader:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-config-reloader
      kubeStateMetrics:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: kubernetes/kube-state-metrics
      admissionWebhook:
        patch:
          image:
            registry: arohcpsvcdev.azurecr.io
            repository: k8s-cache/ingress-nginx/kube-webhook-certgen
            tag: v1.5.2
  # MGMT cluster specifics
  mgmt:
    hcpBackups:
      storageAccount:
        name: "oadp{{ .ctx.environment }}{{ .ctx.regionShort }}{{ .ctx.stamp }}" # [globally-unique]
        zoneRedundantMode: Auto
        public: false
      storageAccountContainerName: "backups"
    subscription:
      usePlannedQuota: true
      key: "hcp-{{ .ctx.environment }}-mgmt-{{ .ctx.region }}-{{ .ctx.stamp }}"
      displayName: "Azure Red Hat OpenShift HCP - {{ .ev2.regionFriendlyName }} - MGMT - {{ .ctx.stamp }}"
      providers:
        'Microsoft.Insights':
          poll: true
        'Microsoft.Storage':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
    rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}-mgmt-{{ .ctx.stamp }}"
    applyKubeletFixes: true
    nsp:
      name: nsp-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}
    aks:
      name: "{{ .ctx.environment }}-{{ .ctx.region }}-mgmt-{{ .ctx.stamp }}" # [env-unique]
      vnetAddressPrefix: "10.128.0.0/14"
      subnetPrefix: "10.128.8.0/21"
      podSubnetPrefix: "10.128.64.0/18"
      kubernetesVersion: 1.32.5
      networkDataplane: "azure"
      networkPolicy: "azure"
      etcd:
        name: "ah-{{ .ctx.environment }}-me-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
        softDelete: true
        private: true
        tagKey: aroHCPPurpose
        tagValue: etcd-encryption
      systemAgentPool:
        vmSize: 'Standard_E8ds_v6'
        osDiskSizeGB: 128
        minCount: 1
        poolCount: 3
        zones: ""
        zoneRedundantMode: "Auto"
      userAgentPool:
        vmSize: 'Standard_E32ds_v6'
        osDiskSizeGB: 512
        minCount: 1
        poolCount: 3
        zones: ""
        zoneRedundantMode: "Auto"
      infraAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D4ds_v5'
        osDiskSizeGB: 32
        poolCount: 2
        zones: ""
        zoneRedundantMode: "Auto"
      clusterOutboundIPAddressIPTags: ""
      enableSwiftV2Vnet: true
      enableSwiftV2Nodepools: true
    prometheus:
      namespace: prometheus
      namespaceNetworkPolicyGroup: monitoring
      prometheusOperator:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-operator
        version: ""
      prometheusSpec:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus
        resources:
          requests:
            cpu: NONE
            memory: NONE
          limits:
            cpu: NONE
            memory: NONE
        replicas: 2
        shards: 2
      prometheusConfigReloader:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-config-reloader
      kubeStateMetrics:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: kubernetes/kube-state-metrics
      admissionWebhook:
        patch:
          image:
            registry: arohcpsvcdev.azurecr.io
            repository: k8s-cache/ingress-nginx/kube-webhook-certgen
            tag: v1.5.2
  # Backend
  backend:
    image:
      registry: arohcpsvcdev.azurecr.io
      repository: arohcpbackend
    tracing:
      address: ""
      exporter: ""
    managedIdentityName: backend
    k8s:
      replicas: 2
      namespace: aro-hcp
      serviceAccountName: backend
  # Admin API
  adminApi:
    image:
      registry: arohcpsvcdev.azurecr.io
      repository: arohcpadminapi
    managedIdentityName: admin-api
    k8s:
      replicas: 2
      namespace: aro-hcp-admin-api
      serviceAccountName: admin-api
    cert:
      name: admin-api-cert-{{ .ctx.environment }}-{{ .ctx.regionShort }}
  # Frontend
  frontend:
    audit:
      connectSocket: false
    image:
      registry: arohcpsvcdev.azurecr.io
      repository: arohcpfrontend
    tracing:
      address: ""
      exporter: ""
    managedIdentityName: frontend
    k8s:
      replicas: 2
      namespace: aro-hcp
      serviceAccountName: frontend
    cosmosDB:
      deploy: true
      disableLocalAuth: true
      name: "arohcp{{ .ctx.environment }}-rp-{{ .ctx.regionShort }}" # [globally-unique]
      private: true
      zoneRedundantMode: 'Auto'
    cert:
      name: frontend-cert-{{ .ctx.environment }}-{{ .ctx.regionShort }}
  # Billing
  billing:
    rg: "placeholder"
    aub:
      accountName: ""
      cloudSuffix: ""
    pav2:
      cloudName: ""
    kusto:
      sku: ""
      clusterName: ""
      clusterPrincipals:
      - name: ""
        id: ""
        role: ""
        tenantId: ""
        type: ""
      dstsGroups:
      - name: ""
        description: ""
      vmUsageStaleThreshold: ""
    eventHub:
      namespace: ""
      subscriptionId: ""
      resourceGroupName: ""
    imageArtifact:
      adoProject: ""
      artifactName: ""
      buildId: 0
  # Mise
  mise:
    deploy: true
    arm:
      policyLabel: "ARM Policy"
      tenantId: "{{ .ev2.entra.tenants.azure.tenantid }}"
      authorityFQDN: "{{ .ev2.entra.fqdn.login }}"
      audienceFQDN: "{{ .ev2.arm.endpoint }}"
    genevaActions:
      policyLabel: "Geneva Actions"
      authorityFQDN: "{{ .ev2.entra.fqdn.sts }}"
      audienceFQDN: "{{ .ev2.arm.endpoint }}"
    image:
      repository: "mise-1p-container-image"
      digest: ""
    tracing:
      address: ""
      exporter: ""
  # MSI RP
  msiRp:
    dataPlaneAudienceResource: https://dummy.org
  # MSI Credentials Refresher
  msiCredentialsRefresher:
    managedIdentityName: msi-credential-refresher
    firstPartyAppClientId: ""
    k8s:
      namespace: msi-credential-refresher
      serviceAccountName: msi-credential-refresher
    image:
      registry: "empty-sentinel"
      repository: "empty-sentinel"
      digest: ""
    certificate:
      name: "msi-refresher"
      manage: true
      issuer: OneCertV2-PrivateCA
      commonName: ""
      sanDnsNames: []
    earlyRefreshFrequency: "0"
    imageArtifact:
      adoProject: ""
      artifactName: ""
      buildId: 0
  # Maestro
  maestro:
    server:
      tracing:
        address: ""
        exporter: ""
      mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
      loglevel: 2
      managedIdentityName: maestro-server
      k8s:
        replicas: 3
        namespace: maestro
        serviceAccountName: maestro
    agent:
      consumerName: "hcp-underlay-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}" # [env-unique]
      loglevel: 2
      managedIdentityName: maestro-consumer
      k8s:
        replicas: 3
        namespace: maestro
        serviceAccountName: maestro
      sidecar:
        image:
          registry: mcr.microsoft.com
          repository: azurelinux/base/nginx
    eventGrid:
      name: "arohcp-{{ .ctx.environment }}-maestro-{{ .ctx.regionShort }}" # [globally-unique]
      maxClientSessionsPerAuthName: 6
      private: false
    postgres:
      name: "arohcp-{{ .ctx.environment }}-dbmaestro-{{ .ctx.regionShort }}" # [globally-unique]
      serverVersion: '15'
      serverStorageSizeGB: 32
      deploy: true
      private: false
      password: ''
      minTLSVersion: 'TLSV1.2'
      databaseName: maestro
      zoneRedundantMode: 'Auto'
      backupRetentionDays: 7
      geoRedundantBackup: false
      containerizedDb:
        image: ""
        pvcCapacity: ""
    restrictIstioIngress: true
    certDomain: ""
    image:
      registry: quay.io
      repository: redhat-user-workloads/maestro-rhtap-tenant/maestro/maestro
  # PKO
  pko:
    managedIdentityName: package-operator
    k8s:
      namespace: package-operator-system
      serviceAccountName: package-operator
    imagePackage:
      registry: quay.io
      repository: package-operator/package-operator-package
      digest: sha256:6dc4ef7c2ac37438636fd18cda973f53440478c91f580fa5e15c6377f41d60c6 # v1.18.3 (2025-12-03 16:28)
    imageManager:
      registry: quay.io
      repository: package-operator/package-operator-manager
      digest: sha256:e9f66a19bc9dcfcf2a9e6ba14f61395806b65813a89385a2f943fe5148b29142 # v1.18.3 (2025-12-03 16:28)
    remotePhaseManager:
      registry: quay.io
      repository: package-operator/remote-phase-manager
      digest: sha256:0298985d8a02c983be382d351e9243c45edd035b11aa23a6ed077b3d6df7aa45 # v1.18.3 (2025-12-03 16:28)
  # ACM
  acm:
    operator:
      bundle:
        registry: quay.io
        repository: redhat-user-workloads/crt-redhat-acm-tenant/acm-operator-bundle-acm-215
        digest: sha256:c4b42034575178a2df9cb15f7ff8e3b5e71e1ee2d1b45a9d9a7ae21d998ec511 # v2.15.1-330 (2026-01-15 05:13)
    mce:
      bundle:
        registry: quay.io
        repository: redhat-user-workloads/crt-redhat-acm-tenant/mce-operator-bundle-mce-210
        digest: sha256:3c36ee1ed07dfbc557783ecaeeb292c95d39e1879f638627c1c7708c6c12b222 # v2.10.1-327 (2026-01-16 05:13)
  # Cluster Service
  clustersService:
    image:
      registry: quay.io
      repository: app-sre/aro-hcp-clusters-service
    # controls how many HCPs can be placed on an MC, sadly not configurable per MC
    provisionShardClusterLimit: 100
    # batch processes
    batchProcessesDryRun: true
    batchProcesses: ""
    # controls if debug jobs are deployed to the cluster.
    deployDebugJobs: false
    tracing: # NOTE: Currently only enabled for pers.
      address: ""
      exporter: ""
    environment: "arohcp{{ .ctx.environment }}"
    denyAssignments: "disabled"
    postgres:
      name: "arohcp-{{ .ctx.environment }}-dbcs-{{ .ctx.regionShort }}" # [globally-unique]
      deploy: true
      private: false
      password: ''
      minTLSVersion: 'TLSV1.2'
      serverVersion: '17'
      serverStorageSizeGB: 128
      databaseName: clusters-service
      zoneRedundantMode: 'Auto'
      backupRetentionDays: 7
      geoRedundantBackup: false
      containerizedDb:
        image: ""
        pvcCapacity: ""
    managedIdentityName: clusters-service
    k8s:
      replicas: 3
      namespace: clusters-service
      serviceAccountName: clusters-service
      deploymentStrategy:
        rollingUpdate:
          maxUnavailable: 0
          maxSurge: 1
    azureRuntimeConfig:
      tlsCertificatesIssuer: OneCertV2-PublicCA
    # OCP Versions configuration
    ocpVersions:
      defaultVersion:
        version: 4.20.8
      channelGroups:
        stable:
          minVersion: 4.19.0
          maxVersion: 4.20.9
        candidate:
          minVersion: ""
          maxVersion: ""
        nightly:
          minVersion: ""
          maxVersion: ""
  # Image Sync
  imageSync:
    environmentName: aro-hcp-image-sync
    outboundServiceTags: ""
    ondemandSync:
      pullSecretName: component-sync-pull-secret
    ocMirror:
      enabled: true
      jobNamePrefix: '{{ .ctx.environment }}-'
      image:
        registry: arohcpsvcdev.azurecr.io
        repository: image-sync/oc-mirror
      pullSecretName: ocmirror-pull-secret
      operatorVersionsToMirror: "4.18,4.19,4.20"
  # Automation Account
  automationDryRun: true
  # Mock Managed Identities - not relevant for most MSFT envs
  miMockClientId: ""
  miMockPrincipalId: ""
  miMockCertName: ""
  armHelperClientId: ""
  armHelperFPAPrincipalId: ""
  armHelperCertName: ""
  # OIDC
  oidc:
    storageAccount:
      name: "arohcp{{ .ctx.environment }}oidc{{ .ctx.regionShort }}" # [globally-unique]
      zoneRedundantMode: Auto
      public: false
      privateLinkLocation: "{{ .ctx.region }}"
    frontdoor:
      manage: true
      subdomain: oic
      name: arohcp{{ .ctx.environment }}
      sku: Premium_AzureFrontDoor
      keyVault:
        name: "ah-{{ .ctx.environment }}-afd" # [globally-unique]
        private: false
        softDelete: true
        tagKey: aroHCPPurpose
        tagValue: afd
      useManagedCertificates: true
      msiName: arohcp-afd
  # Service Key Vault
  serviceKeyVault:
    name: "arohcp{{ .ctx.environment }}-svc-{{ .ctx.regionShort }}" # [globally-unique]
    rg: "{{ .ctx.region }}-shared-resources"
    region: "{{ .ctx.region }}"
    softDelete: false
    private: false
    assignNSP: true
    tagKey: aroHCPPurpose
    tagValue: service
  # Management Cluster KV
  cxKeyVault:
    name: "ah-{{ .ctx.environment }}-cx-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
    tagKey: aroHCPPurpose
    tagValue: cx
  msiKeyVault:
    name: "ah-{{ .ctx.environment }}-mi-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
    tagKey: aroHCPPurpose
    tagValue: msi
  mgmtKeyVault:
    name: "ah-{{ .ctx.environment }}-mg-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
    tagKey: aroHCPPurpose
    tagValue: mgmt
  e2e:
    prow:
      globalKeyVaultTokenSecret: "prow-token"
    regionTest:
      prowJobName: ""
      gatePromotion: true
clouds:
  dev:
    # this configuration serves as a template for for all RH DEV subscription deployments
    defaults:
      kusto:
        kustoName: "hcp-dev-us"
        manageInstance: true
        sku: "Dev(No SLA)_Standard_D11_v2"
        tier: "Basic"
        adminGroups: "6b6d3adf-8476-4727-9812-20ffdef2b85c"
        viewerGroups: "64dc69e4-d083-49fc-9569-ebece1dd1408/6b6d3adf-8476-4727-9812-20ffdef2b85c"
        rg: "hcp-kusto-us"
      tenantId: "64dc69e4-d083-49fc-9569-ebece1dd1408"
      kubeEvents:
        enabled: false
      automationDryRun: false
      arobit:
        mdsd:
          enabled: false
        kusto:
          enabled: true
          environmentName: "dev"
      regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}
      global:
        rg: global
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
        region: westus3
        globalMSIName: global-rollout-identity
        keyVault:
          name: arohcpdev-global
      # DNS
      dns:
        baseDnsZoneRG: global
        cxParentZoneName: hcp.osadev.cloud
        svcParentZoneName: hcpsvc.osadev.cloud
        parentZoneName: osadev.cloud
        globalCertificatesDomain: hcp-global.osadev.cloud
      # Mise
      mise:
        deploy: false
        arm:
          applicationId: "e2c2ff5c-e5b4-4e79-8c3e-1da8c48461e7"
        image:
          digest: sha256:4822b1998fafa4c7ed1e0723dfed8fd0562e1525545327b821e6d9ef29573c74 # 1.39.0-azurelinux3.0-distroless
      # 1P app
      firstPartyAppClientId: b3cb2fab-15cb-4583-ad06-f91da9bfe2d1
      firstPartyAppCertificate:
        name: firstPartyCert2
        issuer: Self
        manage: false
      # Mock Managed Identities Service Princiapl
      miMockClientId: e8723db7-9b9e-46a4-9f7d-64d75c3534f0
      miMockPrincipalId: d6b62dfa-87f5-49b3-bbcb-4a687c4faa96
      miMockCertName: msiMockCert2
      # ARM Helper
      armHelperClientId: 3331e670-0804-48e8-a086-6241671ddc93
      armHelperFPAPrincipalId: 47f69502-0065-4d9a-b19b-d403e183d2f4
      armHelperCertName: armHelperCert2
      # OIDC
      oidc:
        storageAccount:
          public: true
        frontdoor:
          name: arohcpdev
          manage: false
      # Maestro
      maestro:
        certDomain: selfsigned.maestro.keyvault.azure.com
        certIssuer: Self
        image:
          digest: sha256:49b94994c17a989c2c9eed57c1da82f1d6d72ef8d731ece19ee4cce8c095c5c9 # 0f527cd4d82aa01b0e751f886e0099e9e553ec59 (2026-01-14 06:06)
        agent:
          sidecar:
            image:
              digest: sha256:6b8ca92221f842cd3e1ea3f863a324221cc5cf9e54f47dc76092d9582e0a1807 # 1.25.4-6-azl3.0.20260107 (2026-01-07 23:15)
      # ACR Pull
      acrPull:
        image:
          digest: sha256:0129450f2cb03f2d358ac5ac3f46af923f1384fda24cd1b6ace309bb45efc691 # v0.1.21 (2025-12-03 19:29)
      # Secret Sync Controller
      secretSyncController:
        image:
          digest: sha256:399febaa4c537111589a8a52dea7d1ec4cecce8c3d1010729e875a2e305a2f07 # v0.0.2 (2025-07-17 15:49)
        providerImage:
          digest: sha256:c34ca57730d55189e843ebfb8343ef6b865e73b80adc3fd43f6181227c1320a7 # v1.7.2 (2025-11-18 22:23)
      # Cluster Service
      clustersService:
        environment: "arohcpdev"
        image:
          digest: sha256:4e7da86c27ca830f4b46eefa0aed54bd234749fc77137dda1cd3223665752d99 # edfadaaefccbf13a98b2873c9c72d0fc811e9f0d (2026-01-16 16:22)
        azureOperatorsManagedIdentities:
          roleSetName: dev
        azureRuntimeConfig:
          tlsCertificatesIssuer: Self
        # OCP Versions configuration
        ocpVersions:
          channelGroups:
            candidate:
              minVersion: 4.19.7
            nightly:
              minVersion: 4.19.0-0.nightly-20200101
      # Hypershift Operator
      hypershift:
        image:
          registry: quay.io
          repository: redhat-services-prod/crt-redhat-acm-tenant/hypershift/hypershift-operator
          digest: sha256:78746d6478688b54ec477e05768591a07b95baee031ca3faed7779f9d7d46861 # 2ff5e342f5fd18df4d3833e602d2d9b4f669983d (2026-01-13 10:41)
      # Backplane API
      backplaneAPI:
        image:
          digest: sha256:82ffc6763ac1664a6819abbeecaeab21485ee7661d811048fe3d8b3434283851 # 28105e1 (2026-01-15 11:48)
      # Admin API
      adminApi:
        image:
          digest: sha256:87f1ee30987b9bc04ea217b2ffbc1fb2d77f55c2e6cbad6442f0a5bd3b8f31a4 # c428c1f (2026-01-16 15:49)
        cert:
          issuer: Self
      # Frontend
      frontend:
        cert:
          issuer: Self
        image:
          digest: sha256:adf8cdcc646d5750fadc049d569cd7d527ed1ab464c3511dd842d222ce1c15af # c428c1f (2026-01-16 15:49)
      # Backend
      backend:
        image:
          digest: sha256:0f75dcb1291282371a6fc654846c94c6f1fddbdae9326d0e46de4eb29a327f96 # c428c1f (2026-01-16 15:50)
      # Image Sync
      imageSync:
        ocMirror:
          jobNamePrefix: ''
          image:
            digest: sha256:d706d89993827fe2735882336b915fd08e6bde10129725c480ddf5a9455b072d # c428c1f (2026-01-16 15:49)
      # Shared SVC KV
      serviceKeyVault:
        name: 'aro-hcp-dev-svc-kv'
        rg: 'global'
        region: 'westus3'
        softDelete: true
      # MSI Credentials Refresher
      msiCredentialsRefresher:
        certificate:
          manage: false
      svc:
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
          certificateDomains:
          - '*.hcpsvc.osadev.cloud'
        nsp:
          accessMode: 'Learning'
        istio:
          targetVersion: "asm-1-25"
          versions: "asm-1-25"
        aks:
          etcd:
            softDelete: false
          infraAgentPool:
            poolCount: 1
            vmSize: 'Standard_D2s_v3'
          systemAgentPool:
            poolCount: 1
        prometheus:
          prometheusConfigReloader:
            image:
              sha: d3787bb11a5dcce60a843d50e1b2ed6a6d79a8078884f87d07cbbb93c21f6a63 # v0.88.0 (2026-01-12 19:57)
          kubeStateMetrics:
            image:
              digest: sha256:377bd55d97824dfee27b3c577869bc793fc3970623433627c7f0ee1b1b74e725 # v2.17.0 (2025-11-20 19:25)
          prometheusOperator:
            image:
              sha: 024d81f047c4b57adf38bc1ed2893ec06d468caa090ac248984e5808f37e117e # v0.88.0 (2026-01-12 19:57)
          prometheusSpec:
            image:
              sha: 8c051b2f9ff25f35e2d9e64137923c9d7d471d7bcaeb0c1713cfc52c83c50f6e # v3.9.1 (2026-01-09 15:05)
            shards: 1
      mgmt:
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
          certificateDomains:
          - '*.hcp.osadev.cloud'
          - '*.hcpsvc.osadev.cloud'
        aks:
          # MGMTM AKS nodepools - big enough for 2 HCPs
          systemAgentPool:
            vmSize: 'Standard_E8s_v3'
            maxCount: 4
            poolCount: 1
          userAgentPool:
            maxCount: 14
            vmSize: 'Standard_D4s_v3'
            osDiskSizeGB: 100
          infraAgentPool:
            poolCount: 2
            vmSize: 'Standard_D2s_v3'
          etcd:
            softDelete: false
          enableSwiftV2Vnet: false
          enableSwiftV2Nodepools: false
        nsp:
          accessMode: 'Learning'
        prometheus:
          prometheusConfigReloader:
            image:
              sha: d3787bb11a5dcce60a843d50e1b2ed6a6d79a8078884f87d07cbbb93c21f6a63 # v0.88.0 (2026-01-12 19:57)
          kubeStateMetrics:
            image:
              digest: sha256:377bd55d97824dfee27b3c577869bc793fc3970623433627c7f0ee1b1b74e725 # v2.17.0 (2025-11-20 19:25)
          prometheusOperator:
            image:
              sha: 024d81f047c4b57adf38bc1ed2893ec06d468caa090ac248984e5808f37e117e # v0.88.0 (2026-01-12 19:57)
          prometheusSpec:
            image:
              sha: 8c051b2f9ff25f35e2d9e64137923c9d7d471d7bcaeb0c1713cfc52c83c50f6e # v3.9.1 (2026-01-09 15:05)
            shards: 1
      # ACRs
      acr:
        svc:
          name: 'arohcpsvcdev' # [globally-unique]
          zoneRedundantMode: Disabled
        ocp:
          name: 'arohcpocpdev' # [globally-unique]
          zoneRedundantMode: Disabled
      # Metrics
      monitoring:
        icm:
          manageConnection: false
        grafanaName: arohcp-dev
        grafanaMajorVersion: '11'
        grafanaZoneRedundantMode: Disabled
        grafanaRoles: >-
          6b6d3adf-8476-4727-9812-20ffdef2b85c/Group/Admin
        svcWorkspaceName: 'services-{{ .ctx.regionShort }}'
        hcpWorkspaceName: 'hcps-{{ .ctx.regionShort }}'
      kvCertOfficerPrincipalId: 'c9b1819d-bb29-4ac2-9abe-39e4fe9b59eb'
      kvCertAccessPrincipalId: 'c9b1819d-bb29-4ac2-9abe-39e4fe9b59eb'
      kvCertAccessRoleId: ""
      geneva:
        actions:
          application:
            useSNI: false
            name: "arohcp-ga-dev" # [tenant-unique]
            ownerIds: "d8837611-f550-4f0a-af48-575a7178adfb,16ea1e12-7ef3-4613-bea4-3d4a20cbc38c,770ce6b0-5afe-472d-ac0d-1fae72acc4e4" # aro-github-actions-identity, bvesel, goberlec
          keyVault:
            name: "arohcpdev-geneva-kv" # [globally-unique]
          certificate:
            issuer: Self
    environments:
      dev:
        # this is the integrated DEV environment
        defaults:
          regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}
          mgmt:
            aks:
              systemAgentPool:
                maxCount: 4
              # MC AKS nodepools
              # big enough for multiple HCPs
              userAgentPool:
                minCount: 1
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.region }}'
          # Maestro
          maestro:
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}-dev'
              tracing:
                address: "http://ingest.observability:4318"
                exporter: "otlp"
          # Frontend
          frontend:
            audit:
              connectSocket: false
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
      cspr:
        # this is the cluster service PR check and full cycle test environment
        defaults:
          regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          monitoring:
            svcWorkspaceName: 'services-{{ .ctx.environment }}-{{ .ctx.regionShort }}'
            hcpWorkspaceName: 'hcps-{{ .ctx.environment }}-{{ .ctx.regionShort }}'
          svc:
            aks:
              # MC AKS nodepools
              # big enough for multiple CS instances during PR checks
              userAgentPool:
                minCount: 2
                maxCount: 12
          mgmt:
            aks:
              systemAgentPool:
                minCount: 1
                maxCount: 4
              # MC AKS nodepools
              # big enough for multiple HCPs
              userAgentPool:
                minCount: 1
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
          # Geneva
          geneva:
            logs:
              manageCertificates: false
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.region }}-cs'
          # Maestro
          maestro:
            restrictIstioIngress: false
          # Frontend
          frontend:
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
      pers:
        # Regional overrides
        regions:
          switzerlandnorth:
            oidc:
              storageAccount:
                privateLinkLocation: germanywestcentral
          westus:
            oidc:
              storageAccount:
                privateLinkLocation: westus3
          westeurope:
            svc:
              aks:
                userAgentPool:
                  zones: '1'
                infraAgentPool:
                  zones: '1'
                  vmSize: 'Standard_D2s_v3'
                systemAgentPool:
                  zones: '1'
            mgmt:
              aks:
                userAgentPool:
                  zones: '1'
                infraAgentPool:
                  zones: '1'
                  vmSize: 'Standard_D2s_v3'
                systemAgentPool:
                  zones: '1'
        # this is the personal DEV environment
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # Geneva
          geneva:
            logs:
              manageCertificates: false
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # Maestro
          maestro:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
              tracing:
                address: "http://ingest.observability:4318"
                exporter: "otlp"
          # Backend
          backend:
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # Frontend
          frontend:
            audit:
              connectSocket: false
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # MC
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
                osDiskSizeGB: 32
                vmSize: Standard_D2s_v3
              userAgentPool:
                maxCount: 6
                osDiskSizeGB: 100
                vmSize: Standard_D4s_v3
            jaeger:
              deploy: false
            applyKubeletFixes: false
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            jaeger:
              deploy: true
      perf:
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
              userAgentPool:
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
      swft:
        # this is the personal SWIFT DEV environment
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # Maestro
          maestro:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
          # Frontend
          frontend:
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
          # MC
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
              userAgentPool:
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
              enableSwiftV2Vnet: true
              enableSwiftV2Nodepools: true
            jaeger:
              deploy: false
            applyKubeletFixes: false
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
      prow:
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # Geneva
          geneva:
            logs:
              manageCertificates: false
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # Maestro
          maestro:
            postgres:
              deploy: false
              password: 'TheBlurstOfTimes'
              containerizedDb:
                image: "docker.io/library/postgres:14.2"
                pvcCapacity: 512Mi
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
              tracing:
                address: "http://ingest.observability:4318"
                exporter: "otlp"
          # Backend
          backend:
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # Frontend
          frontend:
            audit:
              connectSocket: false
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # MC
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
                osDiskSizeGB: 32
                vmSize: Standard_D2s_v3
              userAgentPool:
                maxCount: 14
                osDiskSizeGB: 100
                vmSize: Standard_D4s_v3
              infraAgentPool:
                vmSize: Standard_D4ds_v5
            jaeger:
              deploy: false
            applyKubeletFixes: false
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
              infraAgentPool:
                vmSize: Standard_D4ds_v5
            jaeger:
              deploy: true
