$schema: config.schema.json
#
#   A B O U T   N A M I N G
#
# For Azure resource names that need to be unique within a cloud, use {{ .ctx }} variables to ensure uniqueness, e.g.
# - for global, regional and SC naming use {{ .ctx.regionShort }} or {{ .ctx.region }}
# - for MGMT naming additionally use {{ .ctx.stamp }}
#
# We have different requirements for naming uniqueness for Azure resources
#
# - [globally-unique] - a resource needs to be unique within the Azure cloud.
#   This is a technical requirement of Azure for certain resource types
# - [env-unique] - a resource needs to be unique within an ARO HCP environment,
#   so accross all regions of ARO HCP in the same environment.
#   An environment unique names does not need to be unique within the Azure cloud
#
# To implement names, we leverate static strings combined with the {{ .ctx }} variables, e.g.
# - {{ .ctx.environment }} length: 1-4 / starts with a character, may end with a digit
# - {{ .ctx.regionShort }} length: 2-4 / starts with a character, may end with a digit
# - {{ .ctx.region }} very long, up to 20 characters / starts with a character, may end with a digit
# - {{ .ctx.stamp }} used for uniqueness for MGMT stamps within a region / digits only
defaults:
  #
  # All defaults in this section need to be environment and region agnostic.
  #
  region: "{{ .ctx.region }}"
  regionRG: "{{ .ctx.region }}-shared-resources"
  cloud: "{{ .ev2.cloudName }}"
  administration:
    readerGroupIds: []
  # Global scope settings
  global:
    safeDnsIntAppObjectId: "" # intentionally left empty
    subscription:
      key: hcp-global
      displayName: "ARO HCP - {{ .ctx.environment }} - Global"
      providers:
        'Microsoft.Dashboard':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
    rg: global-shared-resources
    globalMSIName: global-ev2-identity
    nsp:
      name: nsp-global
      accessMode: 'Learning'
    keyVault:
      name: 'arohcp{{ .ctx.environment }}-global' # [globally-unique]
      private: false
      softDelete: true
  # ACR
  acr:
    svc:
      name: 'arohcpsvc{{ .ctx.environment }}' # [globally-unique]
      zoneRedundantMode: Enabled
    ocp:
      name: 'arohcpocp{{ .ctx.environment }}' # [globally-unique]
      zoneRedundantMode: Enabled
  # ACR Pull
  acrPull:
    image:
      registry: mcr.microsoft.com
      repository: aks/msi-acrpull
  # Arobit
  arobit:
    forwarder:
      image:
        registry: mcr.microsoft.com
        repository: oss/fluent/fluent-bit
        digest: sha256:667535f49ba225d96395ec8df3dcf9cf5f946facdb69afe1d920ebba3e7a4265
    mdsd:
      enabled: false
      image:
        registry: linuxgeneva-microsoft.azurecr.io
        repository: genevamdsd
        digest: sha256:756d114bbaecec418139b53bdf634a9677f71c5c501a4af901246ef2f2c5d468
  # Secret Sync Controller
  secretSyncController:
    image:
      registry: registry.k8s.io
      repository: secrets-store-sync/controller
  # Backplane API
  backplaneAPI:
    image:
      registry: quay.io
      repository: app-sre/backplane-api
  tenantId: ""
  ev2:
    assistedId:
      certificate:
        keyVault: "empty-sentinel" # we don't need one in public cloud, but we need a value to validate the field
        name: ""
      applicationId: ""
  geneva:
    principalId: ""
    resourceContributor: ""
    cert:
      manageCertificates: false
    metrics:
      cluster:
        account: AzureRedHatOpenShiftCluster
      rp:
        account: AzureRedHatOpenShiftRP
    logs:
      administrators:
        alias: AME\WEINONGW
        securityGroup: AME\TM-AzureRedHatOpenShift-Leads
      typeName: ""
      environment: "Test"
  kusto:
    resourceGroup: ""
    cluster: ""
  # Hypershift
  hypershift:
    image:
      registry: quay.io
      repository: acm-d/rhtap-hypershift-operator
    namespace: hypershift
    additionalInstallArg: ''
  # Log settings
  logs:
    mdsd:
      namespace: logs
      msiName: logs-mdsd
      serviceAccountName: genevabit-aggregator
      cert:
        name: ""
        type: ""
        issuer: ""
      subscriptions: []
    loganalytics:
      enable: false
  # Monitoring
  monitoring:
    grafanaName: "arohcp-{{ .ctx.environment }}"
    # Format:
    #   Multiline string using '>-' YAML block scalar
    #   One item per line, formatted as: UUID/PrincipalType/RoleName
    # Our yaml formatter does not allow >- when there is no value, so remember
    # to chage "" to >- when you add a value.
    grafanaRoles: ""
    svcWorkspaceName: 'services-{{ .ctx.regionShort }}'
    hcpWorkspaceName: 'hcps-{{ .ctx.regionShort }}'
    devAlertingEmails: ""
    sev1ActionGroupIDs: ""
    sev2ActionGroupIDs: ""
    sev3ActionGroupIDs: ""
    sev4ActionGroupIDs: ""
  # SVC cluster specifics
  svc:
    subscription:
      key: "hcp-{{ .ctx.environment }}-svc-{{ .ctx.region }}"
      displayName: "ARO HCP - {{ .ctx.environment }} - svc - {{ .ctx.region }}"
      providers:
        'Microsoft.Dashboard':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
    rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}-svc"
    nsp:
      name: nsp-{{ .ctx.regionShort }}-svc
    istio:
      istioctlVersion: "1.24.1"
      tag: "prod-stable"
      ingressGatewayIPAddressName: "aro-hcp-istio-ingress"
      ingressGatewayIPAddressIPTags: ""
    aks:
      name: "{{ .ctx.environment }}-{{ .ctx.region }}-svc-1" # [env-unique]
      vnetAddressPrefix: "10.128.0.0/14"
      subnetPrefix: "10.128.8.0/21"
      podSubnetPrefix: "10.128.64.0/18"
      kubernetesVersion: 1.32.5
      networkDataplane: "cilium"
      networkPolicy: "cilium"
      systemAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        azCount: {{ .ev2.availabilityZoneCount }}
      userAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        azCount: {{ .ev2.availabilityZoneCount }}
      infraAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        azCount: {{ .ev2.availabilityZoneCount }}
      etcd:
        kvName: "ah-{{ .ctx.environment }}-se-{{ .ctx.regionShort }}-1" # [globally-unique]
        kvSoftDelete: true
      clusterOutboundIPAddressIPTags: ""
    prometheus:
      namespace: prometheus
      namespaceLabel: ""
      prometheusOperator:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-operator
          digest: sha256:a5bf4407cb83dc93d4e29ef680e0a4d621256e0f004822f53b2ff1c592bf2a82
        version: ""
      prometheusSpec:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus
          digest: sha256:2dcc22f4a8ea5c198e1c9eb6e7f04d127c55924da72e0f4334e659633185283c
        version: ""
        replicas: 2
        shards: 2
      prometheusConfigReloader:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-config-reloader
          digest: sha256:b112cdc776c740261d812ab544261b781f9cb3520d7b400a353993d3be9c6df1
  # MGMT cluster specifics
  mgmt:
    subscription:
      key: "hcp-{{ .ctx.environment }}-mgmt-{{ .ctx.region }}-{{ .ctx.stamp }}"
      displayName: "ARO HCP - {{ .ctx.environment }} - svc - {{ .ctx.region }}"
      providers:
        'Microsoft.Storage':
          poll: true
        'Microsoft.Network':
          poll: true
          features:
          - name: AllowBringYourOwnPublicIpAddress
            poll: true
        'Microsoft.Compute':
          poll: true
          features:
          - name: EncryptionAtHost
            poll: true
        'Microsoft.ContainerService':
          poll: true
          features:
          - name: IstioNativeSidecarModePreview
            poll: true
    rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}-mgmt-{{ .ctx.stamp }}"
    applyKubeletFixes: true
    nsp:
      name: nsp-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}
    aks:
      name: "{{ .ctx.environment }}-{{ .ctx.region }}-mgmt-{{ .ctx.stamp }}" # [env-unique]
      vnetAddressPrefix: "10.128.0.0/14"
      subnetPrefix: "10.128.8.0/21"
      podSubnetPrefix: "10.128.64.0/18"
      kubernetesVersion: 1.32.5
      networkDataplane: "azure"
      networkPolicy: "azure"
      etcd:
        kvName: "ah-{{ .ctx.environment }}-me-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
        kvSoftDelete: true
      systemAgentPool:
        vmSize: 'Standard_E8s_v3'
        osDiskSizeGB: 128
        minCount: 1
        azCount: {{ .ev2.availabilityZoneCount }}
      userAgentPool:
        vmSize: 'Standard_D16s_v3'
        osDiskSizeGB: 128
        minCount: 1
        azCount: {{ .ev2.availabilityZoneCount }}
      infraAgentPool:
        minCount: 1
        maxCount: 3
        vmSize: 'Standard_D2s_v3'
        osDiskSizeGB: 32
        azCount: {{ .ev2.availabilityZoneCount }}
      clusterOutboundIPAddressIPTags: ""
      enableSwiftV2Vnet: true
      enableSwiftV2Nodepools: true
    prometheus:
      namespace: prometheus
      namespaceLabel: network.openshift.io/policy-group=monitoring
      prometheusOperator:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-operator
        version: ""
      prometheusSpec:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus
        version: "v2.55.1-3"
        replicas: 2
        shards: 2
      prometheusConfigReloader:
        image:
          registry: mcr.microsoft.com/oss/v2
          repository: prometheus/prometheus-config-reloader
          digest: sha256:b112cdc776c740261d812ab544261b781f9cb3520d7b400a353993d3be9c6df1
  # Backend
  backend:
    image:
      registry: arohcpsvcdev.azurecr.io
      repository: arohcpbackend
    tracing:
      address: ""
      exporter: ""
  # Frontend
  frontend:
    audit:
      tcpAddress: ""
    image:
      registry: arohcpsvcdev.azurecr.io
      repository: arohcpfrontend
    tracing:
      address: ""
      exporter: ""
    cosmosDB:
      deploy: true
      disableLocalAuth: true
      name: "arohcp{{ .ctx.environment }}-rp-{{ .ctx.regionShort }}" # [globally-unique]
      private: true
      zoneRedundantMode: 'Auto'
    cert:
      name: frontend-cert-{{ .ctx.environment }}-{{ .ctx.regionShort }}
  # Mise
  mise:
    deploy: false
    azureAdInstance: ""
    firstPartyAppId: ""
    armInstance: ""
    armAppId: ""
    tenantId: ""
    image:
      repository: ""
      digest: ""
  # MSI RP
  msiRp:
    dataPlaneAudienceResource: https://dummy.org
  # MSI Credentials Refresher
  msiCredentialsRefresher:
    managedIdentityName: msi-credential-refresher
    k8s:
      namespace: msi-credential-refresher
      serviceAccountName: msi-credential-refresher
    image:
      registry: "empty-sentinel"
      repository: "empty-sentinel"
      digest: ""
    certificate:
      name: "msi-refresher"
      manage: true
      issuer: OneCertV2-PrivateCA
  # Maestro
  maestro:
    server:
      tracing:
        address: ""
        exporter: ""
      mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
      loglevel: 4
      managedIdentityName: maestro-server
      k8s:
        namespace: maestro
        serviceAccountName: maestro
    agent:
      consumerName: "hcp-underlay-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}" # [env-unique]
      loglevel: 4
      sidecar:
        image:
          registry: mcr.microsoft.com
          repository: azurelinux/base/nginx
          digest: sha256:f203d7e49ce778f8464f403d2558c5d7162b1b9189657c6b32d4f70a99e0fe83
    eventGrid:
      name: "arohcp-{{ .ctx.environment }}-maestro-{{ .ctx.regionShort }}" # [globally-unique]
      maxClientSessionsPerAuthName: 6
      private: false
    postgres:
      name: "arohcp-{{ .ctx.environment }}-dbmaestro-{{ .ctx.regionShort }}" # [globally-unique]
      serverVersion: '15'
      serverStorageSizeGB: 32
      deploy: true
      private: false
      minTLSVersion: 'TLSV1.2'
      databaseName: maestro
      zoneRedundantMode: 'Auto'
    restrictIstioIngress: true
    certDomain: ""
    image:
      registry: quay.io
      repository: redhat-user-workloads/maestro-rhtap-tenant/maestro/maestro
  # PKO
  pko:
    imagePackage:
      registry: quay.io
      repository: package-operator/package-operator-package
      digest: sha256:7e4f7c28650951bbbd73fb42b4780883118d6289f19a3fed4ba5831d32f5f795
    imageManager:
      registry: quay.io
      repository: package-operator/package-operator-manager
      digest: sha256:f2f24e36b097da44f4b598f930cce6c1658be3381d21d7fdf92d26b4dadd1a2f
    remotePhaseManager:
      registry: quay.io
      repository: package-operator/remote-phase-manager
      digest: sha256:f15aa252f69357fbdb2a1b5141badfe9c1f036c800dbfed9d28dc583044e4b4e
  # ACM
  acm:
    mce:
      # pause to mitigate the CAPI CRD issue
      # - https://redhat-external.slack.com/archives/C075PHEFZKQ/p1748436890103839
      # - https://redhat-internal.slack.com/archives/C057Y3D4E1J/p1749128475749979
      pauseReconciliation: true
  # Cluster Service
  clustersService:
    image:
      registry: quay.io
      repository: app-sre/uhc-clusters-service
    tracing: # NOTE: Currently only enabled for pers.
      address: ""
      exporter: ""
    environment: "arohcp{{ .ctx.environment }}"
    postgres:
      name: "arohcp-{{ .ctx.environment }}-dbcs-{{ .ctx.regionShort }}" # [globally-unique]
      deploy: true
      private: false
      minTLSVersion: 'TLSV1.2'
      serverVersion: '12'
      serverStorageSizeGB: 128
      databaseName: clusters-service
      zoneRedundantMode: 'Auto'
    managedIdentityName: clusters-service
    k8s:
      namespace: clusters-service
      serviceAccountName: clusters-service
  # Image Sync
  imageSync:
    environmentName: aro-hcp-image-sync
    outboundServiceTags: ""
    ondemandSync:
      pullSecretName: component-sync-pull-secret
    ocMirror:
      enabled: true
      image:
        registry: arohcpsvcdev.azurecr.io
        repository: image-sync/oc-mirror
      pullSecretName: ocmirror-pull-secret
  # Mock Managed Identities - not relevant for most MSFT envs
  miMockClientId: ""
  miMockPrincipalId: ""
  miMockCertName: ""
  armHelperClientId: ""
  armHelperFPAPrincipalId: ""
  armHelperCertName: ""
  # OIDC
  oidc:
    storageAccount:
      name: "arohcp{{ .ctx.environment }}oidc{{ .ctx.regionShort }}" # [globally-unique]
      zoneRedundantMode: Auto
      public: false
    frontdoor:
      subdomain: oic
      name: arohcp{{ .ctx.environment }}
      sku: Premium_AzureFrontDoor
      keyVaultName: "" # we don't need one in public cloud, but we need a value to validate the field
      msiName: arohcp-afd
  # Service Key Vault
  serviceKeyVault:
    name: "arohcp{{ .ctx.environment }}-svc-{{ .ctx.regionShort }}" # [globally-unique]
    rg: "{{ .ctx.region }}-shared-resources"
    region: "{{ .ctx.region }}"
    softDelete: false
    private: false
    assignNSP: true
  # Management Cluster KV
  cxKeyVault:
    name: "ah-{{ .ctx.environment }}-cx-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
  msiKeyVault:
    name: "ah-{{ .ctx.environment }}-mi-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
  mgmtKeyVault:
    name: "ah-{{ .ctx.environment }}-mg-{{ .ctx.regionShort }}-{{ .ctx.stamp }}" # [globally-unique]
    softDelete: false
    private: false
clouds:
  dev:
    # this configuration serves as a template for for all RH DEV subscription deployments
    defaults:
      regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}
      global:
        rg: global
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
        region: westus3
        globalMSIName: global-rollout-identity
        keyVault:
          name: arohcpdev-global
      # DNS
      dns:
        baseDnsZoneRG: global
        cxParentZoneName: hcp.osadev.cloud
        svcParentZoneName: hcpsvc.osadev.cloud
        parentZoneName: osadev.cloud
      # 1P app
      firstPartyAppClientId: b3cb2fab-15cb-4583-ad06-f91da9bfe2d1
      firstPartyAppCertificate:
        name: firstPartyCert2
        issuer: Self
        manage: false
      # Mock Managed Identities Service Princiapl
      miMockClientId: e8723db7-9b9e-46a4-9f7d-64d75c3534f0
      miMockPrincipalId: d6b62dfa-87f5-49b3-bbcb-4a687c4faa96
      miMockCertName: msiMockCert2
      # ARM Helper
      armHelperClientId: 3331e670-0804-48e8-a086-6241671ddc93
      armHelperFPAPrincipalId: 47f69502-0065-4d9a-b19b-d403e183d2f4
      armHelperCertName: armHelperCert2
      # OIDC
      oidc:
        storageAccount:
          public: true
        frontdoor:
          name: arohcpdev
      # Geneva Actions
      genevaActions:
        serviceTag: GenevaActionsNonProd
      # Maestro
      maestro:
        certDomain: selfsigned.maestro.keyvault.azure.com
        certIssuer: Self
        image:
          digest: sha256:00e0aa8746725c257b370bdd530ef961eb9b88f8c583d2c848b99264d073d5f3
      # ACR Pull
      acrPull:
        image:
          digest: sha256:c802a91b3b0fe4a3875a03904140a14eb54c8b94db1d510946c9c438d28689c0 #v0.1.14
      # Secret Sync Controller
      secretSyncController:
        image:
          digest: sha256:31535c9687ecf49a8654bdc6baeb0ae498cf1dcf04e73cf1f99c5376f777712a #v0.0.1
        providerImage: mcr.microsoft.com/oss/v2/azure/secrets-store/provider-azure:v1.7.0
      # Cluster Service
      clustersService:
        environment: "arohcpdev"
        image:
          digest: sha256:41c6ff66219ca049036bcfb98e0c134a9315fc8a7b21d20e598f494f94a54649
        # NOTE: The role names must not include commas(,) in the name as the roleNames field
        # here is a comma separated list of role definition names.
        azureOperatorsManagedIdentities:
          clusterApiAzure:
            roleNames: Azure Red Hat OpenShift Cluster API Role - Dev
          controlPlane:
            roleNames: Azure Red Hat OpenShift Control Plane Operator Role - Dev
          cloudControllerManager:
            roleNames: Azure Red Hat OpenShift Cloud Controller Manager - Dev
          ingress:
            roleNames: Azure Red Hat OpenShift Cluster Ingress Operator - Dev
          diskCsiDriver:
            roleNames: Azure Red Hat OpenShift Disk Storage Operator - Dev
          fileCsiDriver:
            roleNames: Azure Red Hat OpenShift File Storage Operator - Dev
          imageRegistry:
            roleNames: Azure Red Hat OpenShift Image Registry Operator - Dev
          cloudNetworkConfig:
            roleNames: Azure Red Hat OpenShift Network Operator - Dev
          kms:
            roleNames: Azure Red Hat OpenShift KMS Plugin - Dev
      # Hypershift Operator
      hypershift:
        image:
          registry: quay.io
          repository: acm-d/rhtap-hypershift-operator
          digest: sha256:caa1da4abd381492c07951575b8e64c6cce499252b697e3f6fade575803b2bcf
      # Backplane API
      backplaneAPI:
        image:
          digest: sha256:822477832a73c7eab7fe27200994f10030f708f4a752f33ded3f8f8eaa0470f6
      # Frontend
      frontend:
        cert:
          issuer: Self
        image:
          digest: '' # if empty uses commit sha of repo
      # Backend
      backend:
        image:
          digest: '' # if empty uses commit sha of repo
      # Image Sync
      imageSync:
        ocMirror:
          image:
            digest: sha256:92dc2b18de0126caa2212f62c54023f6e8ecf12e2025c37a5f4151d0253ae14e
      # Shared SVC KV
      serviceKeyVault:
        name: 'aro-hcp-dev-svc-kv'
        rg: 'global'
        region: 'westus3'
        softDelete: true
      # MSI Credentials Refresher
      msiCredentialsRefresher:
        certificate:
          manage: false
      svc:
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
          certificateDomains:
          - '*.hcpsvc.osadev.cloud'
        nsp:
          accessMode: 'Learning'
        istio:
          targetVersion: "asm-1-25"
          versions: "asm-1-25"
        aks:
          etcd:
            kvSoftDelete: false
          infraAgentPool:
            azCount: 1
          systemAgentPool:
            azCount: 1
        prometheus:
          prometheusOperator:
            image:
              digest: sha256:a5bf4407cb83dc93d4e29ef680e0a4d621256e0f004822f53b2ff1c592bf2a82
          prometheusSpec:
            image:
              digest: sha256:2dcc22f4a8ea5c198e1c9eb6e7f04d127c55924da72e0f4334e659633185283c
            shards: 1
      mgmt:
        subscription:
          key: ARO Hosted Control Planes (EA Subscription 1)
          certificateDomains:
          - '*.hcp.osadev.cloud'
          - '*.hcpsvc.osadev.cloud'
        aks:
          # MGMTM AKS nodepools - big enough for 2 HCPs
          systemAgentPool:
            maxCount: 4
            azCount: 1
          userAgentPool:
            maxCount: 6
            vmSize: 'Standard_D4s_v3'
            osDiskSizeGB: 100
          infraAgentPool:
            azCount: 1
          etcd:
            kvSoftDelete: false
          enableSwiftV2Vnet: false
          enableSwiftV2Nodepools: false
        nsp:
          accessMode: 'Learning'
        prometheus:
          prometheusOperator:
            image:
              digest: sha256:a5bf4407cb83dc93d4e29ef680e0a4d621256e0f004822f53b2ff1c592bf2a82
          prometheusSpec:
            image:
              digest: sha256:2dcc22f4a8ea5c198e1c9eb6e7f04d127c55924da72e0f4334e659633185283c
            shards: 1
      # ACRs
      acr:
        svc:
          name: 'arohcpsvcdev' # [globally-unique]
          zoneRedundantMode: Disabled
        ocp:
          name: 'arohcpocpdev' # [globally-unique]
          zoneRedundantMode: Disabled
      # Metrics
      monitoring:
        grafanaName: arohcp-dev
        devAlertingEmails: "aro-hcp-service-lifecycle-team@redhat.com"
        grafanaMajorVersion: '11'
        grafanaZoneRedundantMode: Disabled
        grafanaRoles: >-
          6b6d3adf-8476-4727-9812-20ffdef2b85c/Group/Admin
      kvCertOfficerPrincipalId: 'c9b1819d-bb29-4ac2-9abe-39e4fe9b59eb'
    environments:
      dev:
        # this is the integrated DEV environment
        defaults:
          regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}
          logs:
            loganalytics:
              enable: true
          mgmt:
            aks:
              systemAgentPool:
                maxCount: 4
              # MC AKS nodepools
              # big enough for multiple HCPs
              userAgentPool:
                minCount: 1
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.region }}'
          # Maestro
          maestro:
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}-dev'
              tracing:
                address: "http://ingest.observability:4318"
                exporter: "otlp"
          # Frontend
          frontend:
            audit:
              tcpAddress: arobit-forwarder.mds.svc.cluster.local:24224
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
      cspr:
        # this is the cluster service PR check and full cycle test environment
        defaults:
          regionRG: hcp-underlay-{{ .ctx.environment }}-{{ .ctx.region }}
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          logs:
            loganalytics:
              enable: true
          monitoring:
            svcWorkspaceName: 'services-{{ .ctx.environment }}-{{ .ctx.regionShort }}'
            hcpWorkspaceName: 'hcps-{{ .ctx.environment }}-{{ .ctx.regionShort }}'
          svc:
            aks:
              # MC AKS nodepools
              # big enough for multiple CS instances during PR checks
              userAgentPool:
                minCount: 2
                maxCount: 12
          mgmt:
            aks:
              systemAgentPool:
                minCount: 1
                maxCount: 4
              # MC AKS nodepools
              # big enough for multiple HCPs
              userAgentPool:
                minCount: 1
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.region }}-cs'
          # Maestro
          maestro:
            restrictIstioIngress: false
          # Frontend
          frontend:
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
      ntly:
        # this is an environment to test the deployability of infra nightly
        defaults:
          regionRG: "{{ .ctx.region }}-shared-resources"
          serviceKeyVault:
            name: "arohcp{{ .ctx.environment }}-svc-{{ .ctx.regionShort }}" # [globally-unique]
            rg: "{{ .ctx.region }}-shared-resources"
            region: "{{ .ctx.region }}"
            softDelete: false
          monitoring:
            svcWorkspaceName: 'aro-hcp-ntly-svc-{{ .ctx.regionShort }}'
            hcpWorkspaceName: 'aro-hcp-ntly-hcp-{{ .ctx.regionShort }}'
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}-ntly'
          # Maestro
          maestro:
            postgres:
              deploy: false
          # Frontend
          frontend:
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
          # MC
          mgmt:
            subscription:
              key: ARO HCP nightly management (EA Subscription)
            applyKubeletFixes: false
          svc:
            subscription:
              key: ARO HCP nightly service (EA Subscription)
      pers:
        # this is the personal DEV environment
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # Maestro
          maestro:
            postgres:
              deploy: false
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
              tracing:
                address: "http://ingest.observability:4318"
                exporter: "otlp"
          # Backend
          backend:
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # Frontend
          frontend:
            audit:
              tcpAddress: arobit-forwarder.mds.svc.cluster.local:24224
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
            tracing:
              address: "http://ingest.observability:4318"
              exporter: "otlp"
          # MC
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
                osDiskSizeGB: 32
                vmSize: Standard_D2s_v3
              userAgentPool:
                maxCount: 6
                osDiskSizeGB: 100
                vmSize: Standard_D4s_v3
            jaeger:
              deploy: false
            applyKubeletFixes: false
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            jaeger:
              deploy: true
      perf:
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
              userAgentPool:
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
      swft:
        # this is the personal SWIFT DEV environment
        defaults:
          # Service Key Vault
          serviceKeyVault:
            assignNSP: false
          # Cluster Service
          clustersService:
            postgres:
              deploy: false
          # DNS
          dns:
            regionalSubdomain: '{{ .ctx.regionShort }}'
          # Maestro
          maestro:
            postgres:
              deploy: false
            server:
              mqttClientName: 'maestro-server-{{ .ctx.regionShort }}'
          # Frontend
          frontend:
            cosmosDB:
              private: false
              zoneRedundantMode: 'Disabled'
          # MC
          mgmt:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-mgmt-{{ .ctx.stamp }}"
              systemAgentPool:
                maxCount: 4
              userAgentPool:
                maxCount: 3
                vmSize: 'Standard_D16s_v3'
                osDiskSizeGB: 128
              enableSwiftV2Vnet: true
              enableSwiftV2Nodepools: true
            jaeger:
              deploy: false
            applyKubeletFixes: false
          # SVC
          svc:
            rg: "hcp-underlay-{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
            aks:
              name: "{{ .ctx.environment }}-{{ .ctx.regionShort }}-svc"
